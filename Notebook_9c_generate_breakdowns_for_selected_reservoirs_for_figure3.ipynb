{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "19ee8ecf",
   "metadata": {},
   "source": [
    "# Train a boosted tree model predicting emission intensity of HP reservoirs and use DALEX to interpret the results\n",
    "### T. Janus\n",
    "### 15/04/24"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbae4449",
   "metadata": {},
   "source": [
    "## Outline:\n",
    "1. Load ML and xAI libraries\n",
    "2. Load emissions and HP production data from file(s) generated in Notebook_9b\n",
    "3. Filter the data to include only the reservoirs and exclude RoR\n",
    "4. Fit and test the ML model\n",
    "5. Import emission interpretations generated in Notebook_7\n",
    "6. Generated figures for the second composite figure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f176a8",
   "metadata": {},
   "source": [
    "## Load ML and xAI libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d82684",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "import pathlib\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Enable the output data from scikit-learn's Pipeline to be in Pandas, rather than numpy ndarray format\n",
    "from sklearn import set_config\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold, KFold\n",
    "set_config(transform_output=\"pandas\")\n",
    "\n",
    "# Load tree-based regression models\n",
    "import catboost as cb\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgbm\n",
    "from catboost import CatBoostRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "from lib.hypertune import HyperTuner, hypertune_model\n",
    "from lib.utils import (\n",
    "    save_model, load_model, plot_gini_feature_importances, plot_permutation_feature_importances,\n",
    "    plot_shap_feature_importances, model_check, plot_scores)\n",
    "from lib.utils import (\n",
    "    calculate_gini_feature_importances, calculate_permutation_feature_importances,\n",
    "    calculate_shap_feature_importances)\n",
    "from lib.utils import model_feature_importances\n",
    "\n",
    "import dalex as dx\n",
    "import shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec7e4e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_feat_importances(\n",
    "        model, X_train, X_test, y_test, title: str = \"Feature importances\",\n",
    "        file_name: str| None = None, **kwargs) -> None:\n",
    "    fig, axs = plt.subplots(2, 2, figsize=(10,7))\n",
    "    fig.suptitle(title)\n",
    "    for ix, ax in enumerate(axs.flat):\n",
    "        if ix == 0:\n",
    "            plot_gini_feature_importances(\n",
    "                model, X_train, 15, \n",
    "                'GINI-based Feature Importances', ax = ax)\n",
    "        if ix == 1:\n",
    "            # Computed on test data\n",
    "            plot_permutation_feature_importances(\n",
    "                model, X_test, y_test, max_vars = 15,\n",
    "                n_repeats = 7,\n",
    "                title='Permutation-based Feature Importances', ax = ax)\n",
    "        if ix == 2:\n",
    "            plot_shap_feature_importances(\n",
    "                model, X_test, \n",
    "                max_vars = 15,\n",
    "                title='Mean SHAP values',\n",
    "                plot_type = 'bar', ax=ax)\n",
    "\n",
    "    fig.delaxes(axs[1,1])\n",
    "    plt.tight_layout()\n",
    "    if file_name:\n",
    "        fig.savefig(file_name, dpi = 300, bbox_inches='tight', **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "920b24bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execution options\n",
    "rerun_initial_fit = False # Rerun initial model fitting\n",
    "simu_type = \"local\" # if 'local' then the models are fit on a local computer using CPU, if 'colab' then\n",
    "                    # the models are intended to be run on the Google colab platform\n",
    "override = True # Saves the model (after fitting) even if saved model already exists\n",
    "fitted_models = set(['xgboost', 'catboost', 'lightgbm'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f470dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and filter tabular data for ML and xAI\n",
    "input_output = pd.read_excel(pathlib.Path(\"intermediate/out_par_em_ifc.xlsx\"))\\\n",
    "    .rename(columns={'Unnamed: 0': 'Reservoir'})\\\n",
    "    .loc[:,['Reservoir', 'flow', 'hp', 'reservoir_type', 'Status', \n",
    "            'res_area', 'em_intensity', 'tot_em_net', 'plant_factor',\n",
    "           'des_head', 'des_flow', 'q_mean_des', 'h_mean_des']]\n",
    "input_output_sto = input_output.loc[~input_output['res_area'].isna()]\n",
    "# Load shp data for plotting\n",
    "input_output_gdf = gpd.read_file(pathlib.Path(\"intermediate/out_par_em_ifc.geojson\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec9e121c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training/validation/cross-validation data\n",
    "X = input_output_sto.loc[\n",
    "    :,\n",
    "    ['des_flow', 'q_mean_des', 'des_head', 'h_mean_des', 'tot_em_net', 'res_area']]\n",
    "y = input_output_sto['em_intensity']\n",
    "# Perform data splitting - use 90% train and 10% test\n",
    "random_seed = 666 # Initialise with the number of the beast to maximize chances of getting lucky\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "    train_test_split(X, y, train_size=0.9, test_size=0.1, random_state=random_seed)\n",
    "X_train_test = pd.concat([X_train, X_test])\n",
    "y_train_test = pd.concat([y_train, y_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7947c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xy_train = pd.concat([X_train, y_train], axis=1)\n",
    "corr_matrix = Xy_train.corr()\n",
    "mask_matrix = np.triu(corr_matrix)\n",
    "plt.figure(figsize=(9,6))\n",
    "sns.set(font_scale=0.7)\n",
    "heatmap = sns.heatmap(corr_matrix, vmin=-1, vmax=1, annot=True, cmap=\"YlGnBu\", mask=mask_matrix)\n",
    "heatmap.set_title('Correlation Matrix Heatmap - all features', fontdict={'fontsize':12}, pad=14);\n",
    "heatmap.tick_params(axis='both', which='major', labelsize=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcfe643f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: We save the model to a separate folder called saved_models but read from bin/regression_models/..\n",
    "# This is done in order to not overwrite alread saved models by error.\n",
    "# The saved files need to be moved/copied manually\n",
    "\n",
    "# Make fast and dirty boosted tree regression fitting first\n",
    "cat_features = [] # If empty then no categorical features included in the model/data\n",
    "if simu_type == \"local\":\n",
    "    em_intensity_model = CatBoostRegressor(loss_function = 'RMSE', task_type=\"CPU\", iterations=5000)\n",
    "elif simu_type == \"colab\":\n",
    "    em_intensity_model = CatBoostRegressor(loss_function = 'RMSE', task_type=\"GPU\" )\n",
    "em_intensity_model_quick_path = pathlib.Path(\"bin/regression_models/em_intensity_model_catboost_quick.cbm\")\n",
    "saved_model_path = pathlib.Path(\"saved_models\")\n",
    "\n",
    "if rerun_initial_fit or not os.path.isfile(em_intensity_model_quick_path):\n",
    "    em_intensity_model.fit(X_train, y_train, cat_features = cat_features, silent=True)\n",
    "    file_path = saved_model_path / \"em_intensity_model_catboost_quick.cbm\"\n",
    "    if not file_path.exists():\n",
    "        em_intensity_model.save_model(\n",
    "            saved_model_path / \"em_intensity_model_catboost_quick.cbm\", format=\"cbm\")\n",
    "    if override:\n",
    "        if not saved_model_path.exists():\n",
    "            saved_model_path.mkdir()\n",
    "        em_intensity_model.save_model(\n",
    "            saved_model_path / \"em_intensity_model_catboost_quick.cbm\", format=\"cbm\")\n",
    "else:\n",
    "    em_intensity_model.load_model(em_intensity_model_quick_path) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a43bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_check(\n",
    "    model=em_intensity_model, \n",
    "    X_train = X_train, X_test = X_test, \n",
    "    y_train = y_train, y_test = y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d80bf5b",
   "metadata": {},
   "source": [
    "## Boosted tree model fitting with hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "240ee61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "override = False # Set override OFF for hypertuned models\n",
    "refit = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb19ae2",
   "metadata": {},
   "source": [
    "### Tune the CATBoost model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bbaa982",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_catboost = hypertune_model(\n",
    "    X_train, y_train, num_evals = 2000, hypertuner=HyperTuner.CATBOOST,\n",
    "    file=os.path.join('bin', 'regression_models', 'catboost_em_intensity.pkl'), override = override)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "099b95a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_catboost.params = {\n",
    "    'silent': True, 'verbose': False, 'logging_level': 'Silent',\n",
    "    'metric_period':100}\n",
    "model_catboost.metric_period = 10000\n",
    "model_catboost.logging_level = 'Silent'\n",
    "model_catboost.verbose = False\n",
    "model_catboost.silent = True\n",
    "if refit:\n",
    "    model_catboost.fit(X_train_test, y_train_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e31ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"CATBOOST MODEL REGRESSION STATISTICS\")\n",
    "print(\"---------------------------------------\")\n",
    "model_check(model=model_catboost, \n",
    "    X_train = X_train, X_test = X_test, \n",
    "    y_train = y_train, y_test = y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e154429e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check feature importances\n",
    "fig, axs = plt.subplots(1,1, figsize=(6,3))\n",
    "plot_shap_feature_importances(\n",
    "                model_catboost, X_train_test,\n",
    "                max_vars = 15,\n",
    "                title=\" \",\n",
    "                plot_type = 'bar', ax=axs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f6e9953",
   "metadata": {},
   "source": [
    "### Tune the XGBoost models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee99a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_xgboost = hypertune_model(\n",
    "    X_train, y_train, num_evals = 1_000, hypertuner=HyperTuner.XGBOOST,\n",
    "    file=os.path.join('bin', 'regression_models', 'xgboost_em_intensity.pkl'), override = override)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15dbda9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrain on full data set (for model explainability analysis)\n",
    "if refit:\n",
    "    model_xgboost.fit(X_train_test, y_train_test)\n",
    "print(\"XGBOOST MODEL REGRESSION STATISTICS\")\n",
    "print(\"---------------------------------------\")\n",
    "model_check(model=model_xgboost, \n",
    "    X_train = X_train, X_test = X_test, \n",
    "    y_train = y_train, y_test = y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47a9c053",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check feature importances\n",
    "fig, axs = plt.subplots(1,1, figsize=(6,3))\n",
    "plot_shap_feature_importances(\n",
    "                model_xgboost, X_train_test,\n",
    "                max_vars = 15,\n",
    "                title=\" \",\n",
    "                plot_type = 'bar', ax=axs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aebdbe5",
   "metadata": {},
   "source": [
    "### Tune the LightGBM models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f89612c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lightgbm = hypertune_model(\n",
    "    X_train, y_train, num_evals = 1_000, hypertuner=HyperTuner.LIGHTGBM,\n",
    "    file=os.path.join('bin', 'regression_models', 'lightgbm_em_intensity.pkl'), override = override)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb1ac89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove warnings in the LightGBM CO2 regression model - ONLY WORKS FOR PRE-TRAINED MODELS\n",
    "# IF TRAINING NEW MODELS - COMMENT OUT AND SEE THE WARNINGS FIRST BEFORE TURNING SOME CONFLICTING\n",
    "# REGRESSION PARAMETERS OFF\n",
    "import lightgbm as lgb\n",
    "\n",
    "model_lightgbm.min_child_samples = None\n",
    "model_lightgbm.min_split_gain=None\n",
    "model_lightgbm.subsample=None\n",
    "model_lightgbm.boosting_type=None\n",
    "model_lightgbm.colsample_bytree=None\n",
    "model_lightgbm.reg_alpha = None\n",
    "model_lightgbm.reg_lambda = None\n",
    "model_lightgbm.params={'verbose': -1, 'verbose_eval' : -1}\n",
    "model_lightgbm.free_raw_data=False\n",
    "# Retrain on full data set (for model explainability analysis)\n",
    "#model_co2_lightgbm.predict_raw_score = False\n",
    "if refit:\n",
    "    model_lightgbm.metric = {'rmse'}\n",
    "    model_lightgbm.fit(X_train_test, y_train_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab17b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"LIGHTGBM MODEL REGRESSION STATISTICS\")\n",
    "print(\"---------------------------------------\")\n",
    "model_check(model=model_lightgbm, \n",
    "    X_train = X_train, X_test = X_test, \n",
    "    y_train = y_train, y_test = y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1dde165",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check feature importances\n",
    "fig, axs = plt.subplots(1,1, figsize=(6,3))\n",
    "plot_shap_feature_importances(\n",
    "                model_lightgbm, X_train_test,\n",
    "                max_vars = 15,\n",
    "                title=\" \",\n",
    "                plot_type = 'bar', ax=axs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e305d00",
   "metadata": {},
   "source": [
    "## Plot feature importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb4a0ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_feat_importances(\n",
    "    model_xgboost, X_train_test, X_train_test, y_train_test, \n",
    "    title = \"Feature importances - XGBoost model\",\n",
    "    file_name = pathlib.Path('figures/model_explanation/feature_importances_xgboost_em_intensity.png'),\n",
    "    transparent=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e6d566",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_feat_importances(\n",
    "    model_catboost, X_train_test, X_train_test, y_train_test, \n",
    "    title = \"Feature importances - CATBoost model\",\n",
    "    file_name = pathlib.Path('figures/model_explanation/feature_importances_catboost_em_intensity.png'),\n",
    "    transparent=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0401e570",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_feat_importances(\n",
    "    model_lightgbm, X_train_test, X_train_test, y_train_test, \n",
    "    title = \"Feature importances - LightGBM model\",\n",
    "    file_name = pathlib.Path('figures/model_explanation/feature_importances_lightgbm_em_intensity.png'),\n",
    "    transparent=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "245e1e66",
   "metadata": {},
   "source": [
    "# Model and predictions explanation with DALEX"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5c6269f",
   "metadata": {},
   "source": [
    "## DALEX instance-level explanations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77353cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_index_by_name(name: str, X: pd.DataFrame, df_full: pd.DataFrame = input_output_sto) -> pd.Int64Index | None:\n",
    "    \"\"\"Uses full dataset with Reservoir column to obtain an index of a row containing the input data for the\n",
    "    reservoir which can be used to select data in the train/test dataset, e.g. for inspecting variable\n",
    "    importance for each reservoir\"\"\"\n",
    "    ix = X[df_full['Reservoir']==name].index\n",
    "    if not ix.empty:\n",
    "        return ix\n",
    "    else:\n",
    "        print(f\"Reservoir with name {name} not found\")\n",
    "        return None\n",
    "    \n",
    "def loc_index_to_iloc(loc_index: pd.Int64Index, data: pd.DataFrame = X_train_test) -> int:\n",
    "    \"\"\" \"\"\"\n",
    "    loc_index_int = int(np.mean(loc_index))\n",
    "    return data.index.get_loc(loc_index_int)\n",
    "\n",
    "def reservoir_names(df_full: pd.DataFrame =input_output_sto) -> List[str]:\n",
    "    return list(df_full['Reservoir'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2bd4139",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns of the data and of the explained for visualisation purposes\n",
    "X_train_test_renamed = X_train_test.rename(\n",
    "    columns = {\n",
    "        \"tot_em_net\": \"emission\",\n",
    "        \"res_area\": \"area\",\n",
    "        \"h_mean_des\": \"hmean/hdes\",\n",
    "        \"des_head\": \"hdes\",\n",
    "        \"q_mean_des\" : \"qmean/qdes\",\n",
    "        \"des_flow\" : \"qdes\"\n",
    "    })\n",
    "\n",
    "model_lightgbm.fit(X_train_test_renamed, y_train_test)\n",
    "model_catboost.fit(X_train_test_renamed, y_train_test)\n",
    "model_xgboost.fit(X_train_test_renamed, y_train_test)\n",
    "exp_xgboost = dx.Explainer(\n",
    "    model_xgboost, X_train_test_renamed, y_train_test, \n",
    "    label='xgboost model em intensity') # Uses dalex model explainer\n",
    "exp_lightgbm = dx.Explainer(\n",
    "    model_lightgbm, X_train_test_renamed, y_train_test, \n",
    "    label='lightgbm model em intensity') # Uses dalex model explainer\n",
    "exp_catboost = dx.Explainer(\n",
    "    model_catboost, X_train_test_renamed, y_train_test, \n",
    "    label='catboost model em intensity') # Uses dalex model explainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa325679",
   "metadata": {},
   "outputs": [],
   "source": [
    "variable = \"y\"\n",
    "yvariable = \"residuals\"\n",
    "exp_xgboost.model_diagnostics().plot(variable=variable, yvariable=yvariable)\n",
    "exp_lightgbm.model_diagnostics().plot(variable=variable, yvariable=yvariable)\n",
    "exp_catboost.model_diagnostics().plot(variable=variable, yvariable=yvariable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3cca93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_xgboost.model_performance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfaba9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_catboost.model_performance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497b75bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_lightgbm.model_performance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6400b327",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_emission_intensity_breakdown(\n",
    "        reservoir_name: str, dataset: pd.DataFrame = X_train_test_renamed, \n",
    "        y_data: pd.Series = y_train_test, model: str = 'lightgbm',\n",
    "        file_location: str = \"figures/model_explanation/\",\n",
    "        print_titles: bool = False,\n",
    "        interaction_preference: int = 1, seed: int | None = 42):\n",
    "    \"\"\" \"\"\"\n",
    "    if model == 'lightgbm':\n",
    "        explainer = exp_lightgbm\n",
    "    elif model == \"xgboost\":\n",
    "        explainer = exp_xgboost\n",
    "    elif model == \"catboost\":\n",
    "        explainer = exp_catboost\n",
    "    else:\n",
    "        raise ValueError(f\"Model {model} not recognized.\")\n",
    "    ix = find_index_by_name(name=reservoir_name, X=dataset, df_full=input_output_sto)\n",
    "    num_row = loc_index_to_iloc(loc_index=ix, data=dataset)\n",
    "    input_reservoir = dataset.iloc[[num_row]]\n",
    "    # Find true emisison intensity value for the reservoir\n",
    "    output_true = y_data.iloc[num_row]\n",
    "    # Find predicted value for reservoir using lightgbm model\n",
    "    cp = explainer.predict_profile(input_reservoir)\n",
    "    output_pred = explainer.predict(input_reservoir)\n",
    "    # Calculate the prediction breakdown\n",
    "    #title = f'GHG emission intensity - {reservoir_name}'\n",
    "    if print_titles:\n",
    "        title = 'GHG emission intensity'\n",
    "    else:\n",
    "        title = \" \"\n",
    "    explanation_sample = explainer.predict_parts(\n",
    "        input_reservoir, \n",
    "        type='break_down_interactions', \n",
    "        interaction_preference = interaction_preference, \n",
    "        random_state = seed,\n",
    "        label=title, B=25) \n",
    "    p1 = explanation_sample.plot(\n",
    "        title=title,\n",
    "        max_vars=10, \n",
    "        bar_width = 15,\n",
    "        vertical_spacing = 0.05,\n",
    "        vcolors=(\"#2471a3\", '#89b38a', '#c7644c'), show=False)\n",
    "    p1.update_layout(\n",
    "        paper_bgcolor='rgba(0,0,0,0)',\n",
    "        plot_bgcolor='rgba(0,0,0,0)',\n",
    "        xaxis=dict(\n",
    "            showgrid=False,  # Remove x-axis grid lines\n",
    "            tickfont=dict(color='black')  # Set x-axis tick font color to black\n",
    "        ),\n",
    "        yaxis=dict(\n",
    "            showgrid=False,  # Remove y-axis grid lines\n",
    "            tickfont=dict(color='black')  # Set y-axis tick font color to black\n",
    "        ),\n",
    "        font=dict(color='black')  # Set general font color to black\n",
    "    )\n",
    "    p1.update_traces(opacity=0.90)\n",
    "    p1.data[0].connector.line.color = 'black'\n",
    "    for shape in p1.layout.shapes:\n",
    "        if shape.type == 'line':\n",
    "            shape.line.color = '#424345'  # Set line color to black\n",
    "            shape.line.width = 2\n",
    "    \n",
    "    file_svg = reservoir_name + \"_breakdown_interactions_em_intensity\" + \".svg\"\n",
    "    file_png = reservoir_name + \"_breakdown_interections_em_intensity\" + \".png\"\n",
    "    p1.write_image(pathlib.Path(file_location) / file_svg)\n",
    "    p1.write_image(pathlib.Path(file_location) / file_png)\n",
    "    return p1, output_true, output_pred, cp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f59509c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"  --  \".join(input_output_sto['Reservoir']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868df8d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "reservoir_names = [\n",
    "    \"Thaphanseik\", \"Sedawgyi\", \"Zawgyi II\", \"Belin\", \"Laza\", \n",
    "    \"Mone Chaung\", \"Yeywa (upper)\",\n",
    "    \"Kyee Ohn Kyee Wa\", \"Hawkham (upper)\", \"Myitsone\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845de00f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick reservoir\n",
    "output_comparison = []\n",
    "for reservoir_name in reservoir_names:\n",
    "    p1plt, output_true, output_pred, cp = plot_emission_intensity_breakdown(\n",
    "        reservoir_name, \n",
    "        model = 'catboost',\n",
    "        dataset = X_train_test_renamed,\n",
    "        seed = 42,\n",
    "        interaction_preference = 2)\n",
    "    output_comparison.append([reservoir_name, output_true, output_pred])\n",
    "    #p1plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "409c8fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "065cb18c",
   "metadata": {},
   "outputs": [],
   "source": [
    "p1plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b61a433",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"True output: {output_true}, Output prediction: {output_pred}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "737608bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot ZawgyiII\n",
    "p1plt, output_true, output_pred, cp = plot_emission_intensity_breakdown(\n",
    "    'Zawgyi II', \n",
    "    model = 'catboost',\n",
    "    dataset = X_train_test_renamed,\n",
    "    seed = 42,\n",
    "    interaction_preference = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e37b191",
   "metadata": {},
   "outputs": [],
   "source": [
    "p1plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea355b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cp.result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "082fd757",
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 = cp.plot(variables = ['qmean/qdes', 'hmean/hdes'], show=False, size=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17eeb23d",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(p1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c8482eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "p1.update_layout(\n",
    "    xaxis=dict(\n",
    "        tickfont=dict(color='rgba(0, 0, 0, 0.8)', size=16),  # Set x-axis tick font color to black\n",
    "        title=dict(font=dict(size=18, color='black'))\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        tickfont=dict(color='rgba(0, 0, 0, 0.8)', size=16),  # Set y-axis tick font color to black\n",
    "        title=dict(font=dict(size=18, color='black'))\n",
    "    ),\n",
    "    xaxis2=dict(\n",
    "        tickfont=dict(color='rgba(0, 0, 0, 0.8)', size=16)  # Set x-axis tick font color to black\n",
    "    ),\n",
    "    yaxis2=dict(\n",
    "        tickfont=dict(color='rgba(0, 0, 0, 0.8)', size=16)  # Set y-axis tick font color to black\n",
    "    ),\n",
    "    title=dict(\n",
    "        text='Ceteris Paribus Plots for Emission Intensity Prediction',  # Main plot title\n",
    "        font=dict(size=18, color='black')  # Increase font size and change color to black for the main title\n",
    "    ),\n",
    "    font=dict(color='black'),\n",
    "    width=1000,\n",
    "    height=450\n",
    ")\n",
    "p1.update_traces(\n",
    "    line=dict(width=3, color='rgba(0, 0, 0, 0.6)'),\n",
    "    opacity=0.70)\n",
    "p1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852c2fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "p1.write_image(\"figures/model_explanation/zagyi2cp3.svg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c950445f",
   "metadata": {},
   "source": [
    "### Display the full dataframe of results with GHG emisions, emisison intensities, and water-resources model derived parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d4856d",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_output_sto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a111c49",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
