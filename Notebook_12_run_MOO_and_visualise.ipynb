{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d19b77a3",
   "metadata": {},
   "source": [
    "## Visualise optimization results\n",
    "### T. Janus\n",
    "### 15/01/2024"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f010746f",
   "metadata": {},
   "source": [
    "## TODO:\n",
    "1. Visualise different dam scenarios on maps (borrow the maps from one of the previous notebooks\n",
    "2. Create a composite figure with tiles using facetgrid etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca8e2b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass, field\n",
    "from typing import ClassVar, Dict, List, Any, Tuple, Set, Tuple, Sequence\n",
    "from typing import TypeAlias, TypeVar, Generic\n",
    "import subprocess\n",
    "import pathlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "from datetime import datetime\n",
    "from parse import parse\n",
    "from ttp import ttp\n",
    "import json\n",
    "import gc\n",
    "import bson\n",
    "import pprint\n",
    "import re\n",
    "import ast\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import networkx as nx\n",
    "\n",
    "import pygmo as pg\n",
    "from tqdm import tqdm\n",
    "\n",
    "import seaborn as sns # for Data visualization\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt # for Data visualization\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "from jinja2 import Template\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "T = TypeVar(\"T\")\n",
    "GenericCollection: TypeAlias = Set[T] | Tuple[T] | List[T]\n",
    "NumType= TypeVar('NumType', int, float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f68912",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_mem_usage(df):\n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n",
    "\n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtype\n",
    "    if col_type != object:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.uint8).min and c_max < np.iinfo(np.uint8).max:\n",
    "                    df[col] = df[col].astype(np.uint8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.uint16).min and c_max < np.iinfo(np.uint16).max:\n",
    "                    df[col] = df[col].astype(np.uint16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.uint32).min and c_max < np.iinfo(np.uint32).max:\n",
    "                    df[col] = df[col].astype(np.uint32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)\n",
    "                elif c_min > np.iinfo(np.uint64).min and c_max < np.iinfo(np.uint64).max:\n",
    "                    df[col] = df[col].astype(np.uint64)\n",
    "            elif str(col_type)[:5] == 'float':\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "\n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n",
    "    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ebdc95",
   "metadata": {},
   "outputs": [],
   "source": [
    "#matplotlib.rcParams['font.family'] = ['monospace', 'sans-serif']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9fcae9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auxiliary functions\n",
    "def read_id_ifc_map(file_name: pathlib.Path = pathlib.Path('outputs/moo/id_to_ifc.json')):\n",
    "    \"\"\"Read the dictionary showing mapping between optimization dam IDs and IFC dam IDs\"\"\"\n",
    "    with open(file_name, 'r') as file:\n",
    "        _id_ifc_map = json.load(file)\n",
    "        return {int(key) : value for key, value in _id_ifc_map.items()}\n",
    "    \n",
    "def set_remap(\n",
    "        value_list: Set[NumType], value_map, missing_val_id: int = -99, \n",
    "        safe: bool = False) -> Set[NumType]:\n",
    "    \"\"\"Map values in a set to new values using a dictionary given in `value_map`\"\"\"\n",
    "    if safe:\n",
    "        id_set = set([value_map.get(value, missing_val_id) for value in value_list])\n",
    "        return id_set\n",
    "    return {value_map[value] for value in value_list}\n",
    "\n",
    "def get_every_n_row(df: pd.DataFrame, n: int) -> pd.DataFrame:\n",
    "    \"\"\"Return every n-th row of a dataframe\n",
    "    Used for 'skimming-down' large chunks of data to help with post-processing\n",
    "    and prototyping visualisation\"\"\"\n",
    "    return df.iloc[::n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdcff9a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class SolutionFileParser:\n",
    "    \"\"\" \"\"\"\n",
    "    file_path: str | pathlib.Path\n",
    "    header_template: ClassVar[str] = \"\"\"\n",
    "Date/time: {{ date_time }}\n",
    "Data file: {{ file_name }}\n",
    "Wall time: {{ wall_time | to_float}} seconds.\n",
    "CPU time: {{ cpu_time | to_float}} seconds.\n",
    "seed: {{ seed | to_int}}\n",
    "num_solutions: {{ num_solutions | to_int}}\n",
    "# pruning steps (# nodes): {{ num_pruning_steps | to_int}}\n",
    "Max policies considered: {{ max_policies | to_int}}\n",
    "Policies considered: {{ num_policies | to_int}}\n",
    "Pruned policies: {{ pruned_policies | to_int}}\n",
    "epsilon: {{ epsilon | to_float}}\n",
    "batch size: {{ batch_size | to_int }}\n",
    "criteria: {{ criteria | ORPHRASE | split(',')}}\n",
    "\"\"\"\n",
    "    solution_template: str = \"\"\n",
    "    header: str = \"\"\n",
    "    solutions: str = \"\"\n",
    "    data: Dict[str, Any] = field(default_factory=dict)\n",
    "    \n",
    "    def __post_init__(self) -> None:\n",
    "        \"\"\" \"\"\"\n",
    "        with open(self.file_path, 'r') as file:\n",
    "            raw_data = file.readlines()\n",
    "            self.header = \"\".join(raw_data[0:13])\n",
    "            self.solutions = \"\".join(raw_data[14:])\n",
    "            \n",
    "    def _create_solution_template(self) -> None:\n",
    "        \"\"\" \"\"\"\n",
    "        sol_template = \"\"\n",
    "        crit_template = \"{{{{ {} | to_float }}}}\"\n",
    "        num_dams_template = \"{{{{ {} | to_int }}}}\"\n",
    "        for criterion in self.data['header']['criteria']:\n",
    "            sol_template += crit_template.format(criterion) + \", \"\n",
    "        sol_template += num_dams_template.format('num_dams') + \", \"\n",
    "        sol_template += \"{{ dam_ids | ORPHRASE | split(' ')}}\"\n",
    "        self.solution_template = sol_template\n",
    "        \n",
    "    def parse(self) -> None:\n",
    "        \"\"\" \"\"\"\n",
    "        # 1. Parse header\n",
    "        parser_header = ttp(self.header, self.header_template)\n",
    "        parser_header.parse()\n",
    "        header_data = parser_header.result(structure=\"flat_list\")[0]\n",
    "        header_data['criteria'] = [criterion.strip() for criterion in header_data['criteria']]\n",
    "        date_time_formatted = re.sub(r'_+', ',', header_data['date_time'])\n",
    "        header_data['date_time'] = datetime.strptime(\n",
    "            date_time_formatted, \"%a,%b,%d,%H,%M,%S,%Y\")\n",
    "        self.data['header'] = header_data\n",
    "        # 2. Dynamically create a solution template\n",
    "        self._create_solution_template()\n",
    "        # 3. Parse solutions\n",
    "        parser_sol = ttp(self.solutions, self.solution_template)\n",
    "        parser_sol.parse()\n",
    "        solution_data = parser_sol.result(structure=\"flat_list\")\n",
    "        for solution in solution_data:\n",
    "            solution['dam_ids'] = [int(dam_id) for dam_id in solution['dam_ids']]\n",
    "        self.data['solutions'] = solution_data\n",
    "        \n",
    "    @property\n",
    "    def solutions_df(self) -> pd.DataFrame:\n",
    "        \"\"\" \"\"\"\n",
    "        df = pd.DataFrame(self.data['solutions'])\n",
    "        if set(['loss_agri', 'loss_forest']).issubset(set(df.columns)):\n",
    "            df['land_loss'] = df['loss_agri'] + df['loss_forest']\n",
    "        # Calculate ghg intensity, for ghg in tonneCO2eq/year and energy in MWh/d\n",
    "        # GHG intensity needs to be in gCO2eq/kWh\n",
    "        df['ghg_intensity'] = df['ghg'] / df['energy'] * 1_000 / 365.25 / 24\n",
    "        return df\n",
    "        \n",
    "        \n",
    "    def to_json(self, json_file: str | pathlib.Path) -> None:\n",
    "        \"\"\" \"\"\"\n",
    "        # Custom serialization function for datetime objects\n",
    "        def serialize_datetime(obj: Any) -> str:\n",
    "            if isinstance(obj, datetime):\n",
    "                return obj.isoformat()\n",
    "        \n",
    "        with open(json_file, 'w') as file:\n",
    "            json_string = json.dumps(self.data, default=serialize_datetime, indent=4)\n",
    "            file.write(json_string)\n",
    "            \n",
    "    def to_bson(self, file_path: str | pathlib.Path) -> None:\n",
    "        with open(file_path, 'wb') as bson_file:\n",
    "            serialized_data = bson.dumps(self.data)\n",
    "            bson_file.write(serialized_data)\n",
    "            \n",
    "    def to_csv(self, csv_file: str | pathlib.Path) -> None:\n",
    "        \"\"\"Save solutions to a csv file.\n",
    "        Dam IDs are saved as a string representation of a list of integers. To retrieve\n",
    "        the list of interegers, parse the dam_ids column\n",
    "        df_read.dam_ids = df_read.dam_ids.map(ast.literal_eval) \n",
    "        (requires `import ast`)\"\"\"\n",
    "        self.solutions_df.to_csv(csv_file, encoding='utf-8', index=False)\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class OutputVisualiser:\n",
    "    \"\"\" \"\"\"\n",
    "    data: pd.DataFrame\n",
    "        \n",
    "    @property\n",
    "    def columns(self) -> List[str]:\n",
    "        \"\"\" \"\"\"\n",
    "        return list(self.data.columns)\n",
    "    \n",
    "    def plot_parallel(\n",
    "            self, columns: GenericCollection[str], color_col: str, title: str | None = None,\n",
    "            color_limits: Tuple[float, float] = (0,200), **kwargs):\n",
    "        \"\"\" \"\"\"\n",
    "        # Other scales:\n",
    "        # px.colors.diverging.Tealrose\n",
    "        # px.colors.sequential.Blues\n",
    "        # px.colors.sequential.Oranges\n",
    "        # px.colors.diverging.RdYlBu\n",
    "        # color_continuous_scale=px.colors.diverging.Armyrose\n",
    "        # color_continuous_midpoint=2\n",
    "        \n",
    "        fig = px.parallel_coordinates(self.data, color=color_col, dimensions=columns,\n",
    "                              color_continuous_scale=px.colors.diverging.Tealrose, width=1000,\n",
    "                              title=title, range_color=color_limits, **kwargs)\n",
    "        fig.show()\n",
    "        return fig\n",
    "        \n",
    "    def plot_scatter_2D(\n",
    "            self, x_col: str, y_col: str, hue: str | None = None, size: str | None = None,\n",
    "            palette: str = \"hot\", xlabel: str | None = None, ylabel: str | None = None) -> None:\n",
    "        \"\"\" \"\"\"\n",
    "        kwargs  =   {\n",
    "             'edgecolor' : \"k\",\n",
    "             'facecolor' : \"w\",\n",
    "             'linewidth' : 0.2,\n",
    "             'linestyle' : '-',\n",
    "            }\n",
    "        \n",
    "        fig, ax = plt.subplots(figsize=(8, 5))\n",
    "        sns.set_style('white')\n",
    "        sns.set_context(\"paper\", font_scale = 1)\n",
    "        sns.despine(right = True)\n",
    "        sns.scatterplot(\n",
    "            x = x_col, y = y_col, data = self.data, hue=hue, palette=palette, size=size,\n",
    "            marker = 'o', **kwargs, alpha = 0.95)\n",
    "        ax.legend(title='Development scenario / Firm Energy, MW', fontsize=10, \n",
    "                  title_fontsize=12, frameon=False,\n",
    "                  ncol=3)\n",
    "        plt.xlabel(xlabel, fontsize=12)\n",
    "        plt.ylabel(ylabel, fontsize=12)\n",
    "        fig.show()\n",
    "        \n",
    "        \n",
    "@dataclass\n",
    "class ObjectiveCalculator:\n",
    "    \"\"\" \"\"\"\n",
    "    obj_df: pd.DataFrame\n",
    "    ids: List[NumType] = field(default_factory = list) # Need to be IFC_IDS\n",
    "    obj_names: ClassVar[List[int]] = [\n",
    "        'HP_mean', 'HP_firm', 'tot_em', 'crop_area_loss_km2', 'forest_area_loss_km2']\n",
    "    \n",
    "    def _filter_df(self) -> Tuple[pd.DataFrame, List[NumType]]:\n",
    "        filtered_df = self.obj_df[self.obj_df.index.isin(self.ids)]\n",
    "        found_indices = filtered_df.index.to_list()\n",
    "        missed_indices = set(self.ids) - set(found_indices)\n",
    "        return filtered_df, list(missed_indices)\n",
    "    \n",
    "    @property\n",
    "    def objectives(self) -> pd.Series:\n",
    "        \"\"\" \"\"\"\n",
    "        return self._filter_df()[0][self.obj_names].sum()\n",
    "\n",
    "    \n",
    "def map_ids(moo_ids: Sequence[int], id_map: Dict[int, int]) -> Sequence[int]:\n",
    "    \"\"\"Takes a sequence of values, e.g. dam IDs and returns a mapped sequence where\n",
    "    the original values are mapped to new values using a dictionary\"\"\"\n",
    "    return [id_map.get(item, item) for item in moo_ids]\n",
    "\n",
    "\n",
    "def find_solution_by_dam_numbers(df: pd.DataFrame, dam_ids: Set[int]) -> pd.DataFrame:\n",
    "    \"\"\"Find row(s) of dataframe matching a specified selected dams by dam id\"\"\"\n",
    "    return df[df['dam_ids']] == dam_ids\n",
    "\n",
    "def return_row_by_criterion(df: pd.DataFrame, criterion: str, value: Any) -> pd.Series:\n",
    "    # Calculate the absolute differences\n",
    "    differences = (df[criterion] - value).abs()\n",
    "    # Find the index of the minimum absolute difference\n",
    "    closest_index = differences.idxmin()\n",
    "    # Return the row using the index\n",
    "    closest_row = df.loc[closest_index]\n",
    "    return closest_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "952c4059",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get built dam IFC ids\n",
    "dam_data = pd.read_csv(pathlib.Path(\"outputs/moo/all_hp.csv\"))\n",
    "built_dam_ifc_ids: Set[int] = set(\n",
    "    dam_data[dam_data['status'] == 'Existing']['ifc_id'].to_list())\n",
    "# Read the ID to IFC map\n",
    "id_ifc_map = read_id_ifc_map()\n",
    "# List IFC IDs in a sorted order of dams included in the analysis\n",
    "ifc_ids = sorted([id_ifc_map[_id+1] for _id, _ in enumerate(id_ifc_map) ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "732d6319",
   "metadata": {},
   "source": [
    "### Define constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152a42f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "mya_nobuilt_5obj_filename = 'mya_5_obj_nobuilt.sol'\n",
    "mya_built_5obj_filename = 'mya_5_obj_built.sol'\n",
    "# Paths to output files from the algorithm with expansion / compression\n",
    "sol_file_folder = pathlib.Path('moo_solver_CPAIOR/outputs/epsilon2_5obj')\n",
    "mya_nobuilt_5obj_path_cpaior = sol_file_folder / pathlib.Path(mya_nobuilt_5obj_filename)\n",
    "mya_built_5obj_path_cpaior = sol_file_folder / pathlib.Path(mya_built_5obj_filename)\n",
    "\n",
    "dam_data_filename = pathlib.Path(\"outputs/moo/all_hp.csv\")\n",
    "    \n",
    "# Load the mapping between ids used in the MOO algorithm and the IDs in the IFC database\n",
    "map_file_path = pathlib.Path('outputs/moo/id_to_ifc.json')\n",
    "with open(map_file_path, 'r') as file:\n",
    "    id_map = json.load(file)\n",
    "id_map = {int(key): value for key, value in id_map.copy().items()} # Maps optim ids to ifc ids\n",
    "ifc_to_id_map = {value: key for key, value in id_map.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b8f69ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "dam_df = pd.read_csv(dam_data_filename, index_col=0).set_index('ifc_id')\n",
    "built_dam_ids_ifc = set(dam_df[dam_df['status_int'] == 1].index.to_list())\n",
    "built_dam_ids_opt = set_remap(built_dam_ids_ifc, ifc_to_id_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65151bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_existing_dams = dam_df[dam_df['status'] == 'Existing']['name'].count()\n",
    "print(f\"Number of existing dams: {num_existing_dams}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88240994",
   "metadata": {},
   "outputs": [],
   "source": [
    "existing_dam_ids = set(dam_df[dam_df['status'] == 'Existing'].index.to_list())\n",
    "print(existing_dam_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f92f7a9",
   "metadata": {},
   "source": [
    "## Call the optimizer by calling external script using subprocess (not recommended)\n",
    "### Better to read pre-calculated solutions as the optimization takes a long time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "208f2dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "rerun_CPAIOR: bool = False\n",
    "\n",
    "# Specify the path to your shell script\n",
    "script_path = 'moo_solver_CPAIOR/run_myanmar_dam_selection.sh'\n",
    "\n",
    "# Use subprocess to call and execute the shell script\n",
    "if rerun_CPAIOR:\n",
    "    try:\n",
    "        subprocess.run(['bash', script_path], check=True)\n",
    "        print(\"Optimization runs successful.\")\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"Error executing script: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e5d76f9",
   "metadata": {},
   "source": [
    "## Parse outputs - 5 objective optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9280ca96",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_to_json: bool = False\n",
    "save_to_csv: bool = False\n",
    "# Parse solutions with no built dams\n",
    "mya_nobuilt_parser_cpaior_5obj = SolutionFileParser(mya_nobuilt_5obj_path_cpaior)\n",
    "mya_nobuilt_parser_cpaior_5obj.parse()\n",
    "if save_to_json:\n",
    "    mya_nobuilt_parser_cpaior_5obj.to_json(sol_file_folder / pathlib.Path('mya_5_obj_nobuilt.json'))\n",
    "if save_to_csv:\n",
    "    mya_nobuilt_parser_cpaior_5obj.to_csv(sol_file_folder / pathlib.Path('mya_5_obj_nobuilt.csv'))\n",
    "# Parse solutions with built dams\n",
    "mya_built_parser_cpaior_5obj = SolutionFileParser(mya_built_5obj_path_cpaior)\n",
    "mya_built_parser_cpaior_5obj.parse()\n",
    "if save_to_json:\n",
    "    mya_built_parser_cpaior_5obj.to_json(sol_file_folder / pathlib.Path('mya_5_obj_built.json'))\n",
    "if save_to_csv:\n",
    "    mya_built_parser_cpaior_5obj.to_csv(sol_file_folder / pathlib.Path('mya_5_obj_built.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c64feab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_rows_to_remove: int = 6  # Remove n rows per n+1 rows, e.g. if value is 3 every 3 out of four rows \n",
    "                            # will be removed\n",
    "filter_dataframe: bool = True\n",
    "\n",
    "# Concetenate dataframes into `merged_df`\n",
    "df_nobuilt = reduce_mem_usage(mya_nobuilt_parser_cpaior_5obj.solutions_df)\n",
    "df_built = reduce_mem_usage(mya_built_parser_cpaior_5obj.solutions_df)\n",
    "\n",
    "# Remove the unwanted objects from memory\n",
    "del mya_nobuilt_parser_cpaior_5obj\n",
    "del mya_built_parser_cpaior_5obj"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c90a399",
   "metadata": {},
   "source": [
    "## Combine dataframes with results with 'built' and 'notbuilt' scenarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "050430d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nobuilt['Scenario'] = \"Not Built\"\n",
    "df_built['Scenario'] = \"Built\"\n",
    "\n",
    "merged_df = pd.concat([df_built, df_nobuilt], ignore_index=True)\n",
    "old_new_col_map = {\n",
    "    'energy': \"Mean annual HP, [MW]\",\n",
    "    'ghg': 'GHG emissions [tonne CO<sub>2,eq</sub>/year]', \n",
    "    'firm_energy': 'Firm HP, [MW]',\n",
    "    'loss_agri': 'Agricultural land loss, [km<sup>2</sup>]',\n",
    "    'loss_forest': 'Deforestation, [km<sup>2</sup>]',\n",
    "    'num_dams': 'No. of selected dams',\n",
    "    'dam_ids': 'Dam IDs',\n",
    "    'land_loss': 'Land loss, [km<sup>2</sup>]',\n",
    "    'ghg_intensity': 'GHG intensity [gCO<sub>2,eq</sub>/kWh]'}\n",
    "merged_df.rename(columns=old_new_col_map, inplace=True)\n",
    "merged_df['Dam IDs'] = merged_df['Dam IDs'].apply(set)\n",
    "merged_df['Firm Power Ratio, [%]'] = merged_df['Firm HP, [MW]'] / merged_df['Mean annual HP, [MW]'] * 100\n",
    "merged_df['Scenario, [1/0]'] = merged_df['Scenario'].map({'Built': 1, 'Not Built': 0})\n",
    "\n",
    "# Define bin edges for land loss\n",
    "bins = [0, 400, 800, 1200, 1600]\n",
    "# Define labels for the bins\n",
    "labels = ['0-400 km2', '400-800 km2', '800-1200 km2', '1200-1600 km2']\n",
    "merged_df[\"Loss of Land [km<sup>2</sup>]\"] = pd.cut(\n",
    "    merged_df['Land loss, [km<sup>2</sup>]'], bins=bins, labels=labels, right=False)\n",
    "# Arrange by status and energy in ascending order\n",
    "merged_df = merged_df.sort_values(by=['Scenario', 'Mean annual HP, [MW]'], ascending=True)\n",
    "# Introduce new columns\n",
    "merged_df['HP Production [GWh/year]'] = merged_df[\"Mean annual HP, [MW]\"] * 365.25 * 24 / 1_000\n",
    "merged_df['Mean HP [GWh/d]'] = merged_df[\"Mean annual HP, [MW]\"] * 24 / 1_000\n",
    "merged_df['Firm HP [GWh/d]'] = merged_df['Firm HP, [MW]'] * 24 / 1_000\n",
    "\n",
    "# Reduce size of some data in merged_df\n",
    "merged_df['Scenario, [1/0]'] = merged_df['Scenario, [1/0]'].astype('uint8')\n",
    "merged_df[\"Loss of Land [km<sup>2</sup>]\"] = merged_df[\"Loss of Land [km<sup>2</sup>]\"].astype('category')\n",
    "merged_df['No. of selected dams'] = merged_df['No. of selected dams'].astype('int8')\n",
    "# Use an automated method\n",
    "merged_df = reduce_mem_usage(merged_df)\n",
    "\n",
    "# Filter the dataframe if filtering is selected\n",
    "if filter_dataframe:\n",
    "    merged_df = get_every_n_row(merged_df, no_rows_to_remove+1)\n",
    "\n",
    "# Perform non-dominated sorting in 2D for two 5D nondominated fronts: for Built and NotBuilt scenarios\n",
    "# Create a pareto dominant front for not built data\n",
    "xy_pairs_list_built = merged_df\\\n",
    "    .loc[merged_df['Scenario'] =='Built', \n",
    "         [\"Mean annual HP, [MW]\", 'GHG emissions [tonne CO<sub>2,eq</sub>/year]', \n",
    "          'GHG intensity [gCO<sub>2,eq</sub>/kWh]', 'Firm Power Ratio, [%]']]\n",
    "xy_pairs_list_built[\"Mean annual HP, [MW]\"] = xy_pairs_list_built[\"Mean annual HP, [MW]\"] * -1\n",
    "xy_pairs_list_built = xy_pairs_list_built.to_numpy().tolist()\n",
    "\n",
    "xy_pairs_list_nobuilt = merged_df\\\n",
    "    .loc[merged_df['Scenario'] =='Not Built', \n",
    "         [\"Mean annual HP, [MW]\", 'GHG emissions [tonne CO<sub>2,eq</sub>/year]', \n",
    "          'GHG intensity [gCO<sub>2,eq</sub>/kWh]', 'Firm Power Ratio, [%]']]\n",
    "xy_pairs_list_nobuilt[\"Mean annual HP, [MW]\"] = xy_pairs_list_nobuilt[\"Mean annual HP, [MW]\"] * -1\n",
    "xy_pairs_list_nobuilt = xy_pairs_list_nobuilt.to_numpy().tolist()\n",
    "\n",
    "xy_pair_array_built = np.array(xy_pairs_list_built)\n",
    "xy_pair_array_nobuilt = np.array(xy_pairs_list_nobuilt)\n",
    "\n",
    "# Find non-dominated fronts\n",
    "non_dom_front_built = pg.non_dominated_front_2d(points=xy_pair_array_built[:,:2])\n",
    "non_dom_front_nobuilt = pg.non_dominated_front_2d(points=xy_pair_array_nobuilt[:,:2])\n",
    "# Convert back from negative to positive values\n",
    "xy_pair_array_built[:,0] = xy_pair_array_built[:,0] * -1\n",
    "xy_pair_array_nobuilt[:,0] = xy_pair_array_nobuilt[:,0] * -1\n",
    "# Select nondominated points\n",
    "xy_nondom_built = xy_pair_array_built[non_dom_front_built]\n",
    "xy_nondom_nobuilt = xy_pair_array_nobuilt[non_dom_front_nobuilt]\n",
    "xy_nondom_all = np.concatenate((xy_nondom_built, xy_nondom_nobuilt), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131012dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the solution ids of the 2D nondominated song in the order of increasing annual energy production\n",
    "# Plot the results (for built and not built scenarios) as a scatterplot\n",
    "em_int_nondom_built = merged_df.loc[merged_df['Scenario'] =='Built'].iloc[non_dom_front_built]\n",
    "em_int_nondom_nobuilt = merged_df.loc[merged_df['Scenario'] =='Not Built'].iloc[non_dom_front_nobuilt]\n",
    "em_int_nondom_df = pd.concat(\n",
    "    [em_int_nondom_built, em_int_nondom_nobuilt], ignore_index=True).sort_values(\"Mean annual HP, [MW]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "708a6e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_to_file: bool = False\n",
    "if save_to_file:\n",
    "    em_int_nondom_df.to_csv('em_int_nondom_df.csv', index=False)\n",
    "    merged_df.to_csv('merged_df.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f40a51ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_from_file: bool = False\n",
    "if load_from_file:\n",
    "    merged_df = pd.read_csv('merged_df.csv')\n",
    "    em_int_nondom_df = pd.read_csv('em_int_nondom_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb6fd21",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Statistics\n",
    "number_of_solutions = len(df_nobuilt) + len(df_built)\n",
    "print(f\"Total number of solutions : {number_of_solutions}\")\n",
    "print(f\"Scenario with built constructed dams {len(df_built)} solutions\")\n",
    "print(f\"Scenario with zero constructed dams {len(df_nobuilt)} solutions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df4acec",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90cd1228",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find a solution with built dams with minumum energy generation (solution with built dams only)\n",
    "built_min = merged_df[merged_df['Scenario']=='Built'].iloc[0]\n",
    "built_min_damids = built_min['Dam IDs']\n",
    "built_min_energy = built_min[\"Mean annual HP, [MW]\"]\n",
    "built_min_ghg_intensity = built_min['GHG intensity [gCO<sub>2,eq</sub>/kWh]']\n",
    "built_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "895535f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find total energy from input data using selected dams as an input\n",
    "oc_built = ObjectiveCalculator(dam_df, ids=set_remap(built_min['Dam IDs'], id_map))\n",
    "print(\n",
    "    f\"Min HP from optimization: {built_min_energy} MW, min HP from input data: {oc_built.objectives['HP_mean']} MW\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0dcdddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "em_int_nondom_df[em_int_nondom_df['Scenario']==\"Built\"].sort_values(by='No. of selected dams').head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f9362ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "dam_ids_7848 = em_int_nondom_df.loc[7848, 'Dam IDs']\n",
    "dam_ids_7599 = em_int_nondom_df.loc[7599, 'Dam IDs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9482800",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get selected data points\n",
    "plot_data = em_int_nondom_df\n",
    "plot_data['HP Production [TWh/year]'] = plot_data['HP Production [GWh/year]'] / 1_000\n",
    "current_solution = (built_min['HP Production [GWh/year]']/1_000, built_min_ghg_intensity)\n",
    "notbuilt_current = return_row_by_criterion(\n",
    "    plot_data[plot_data['Scenario']==\"Not Built\"], \n",
    "    'HP Production [TWh/year]', value=built_min['HP Production [GWh/year]']/1_000)\n",
    "\n",
    "# Get selected data points\n",
    "current_solution = (built_min['HP Production [GWh/year]']/1_000, built_min_ghg_intensity)\n",
    "notbuilt_current = return_row_by_criterion(\n",
    "    plot_data[plot_data['Scenario'] == \"Not Built\"], 'HP Production [TWh/year]', \n",
    "    value=built_min['HP Production [GWh/year]']/1_000)\n",
    "built_100 = return_row_by_criterion(\n",
    "    plot_data[plot_data['Scenario'] == \"Built\"], 'HP Production [TWh/year]', value=100)\n",
    "notbuilt_100 = return_row_by_criterion(\n",
    "    plot_data[plot_data['Scenario'] == \"Not Built\"], 'HP Production [TWh/year]', value=100)\n",
    "built_200 = return_row_by_criterion(\n",
    "    plot_data[plot_data['Scenario'] == \"Built\"], 'HP Production [TWh/year]', value=200)\n",
    "notbuilt_200 = return_row_by_criterion(\n",
    "    plot_data[plot_data['Scenario'] == \"Not Built\"], 'HP Production [TWh/year]', value=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b98dd953",
   "metadata": {},
   "outputs": [],
   "source": [
    "notbuilt_current"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb32a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define bin edges for firm power ratio\n",
    "firm_power_bins = [0, 15, 30, 45, 60, 75, 100]\n",
    "# Define labels for the bins\n",
    "firm_power_labels = ['0%-15%', '15%-30%', '30%-45%', '45%-60%', '60%-75%', '75%-100%']\n",
    "firm_power_bins2 = [0, 25, 50, 75]\n",
    "firm_power_labels2 = ['0%-25%', '25%-50%', '50%-75%']\n",
    "em_int_nondom_df['Firm Power Ratio Cat'] = pd.cut(\n",
    "    em_int_nondom_df['Firm Power Ratio, [%]'], bins=firm_power_bins2, \n",
    "    labels=firm_power_labels2, right=False)\n",
    "merged_df['Firm Power Ratio Cat'] = pd.cut(\n",
    "    merged_df['Firm Power Ratio, [%]'], bins=firm_power_bins, \n",
    "    labels=firm_power_labels, right=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b59bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_x_y_intensity_plot(data: pd.Series) -> Tuple[float, float]:\n",
    "    \"\"\" \"\"\"\n",
    "    return (data['HP Production [TWh/year]'], data['GHG intensity [gCO<sub>2,eq</sub>/kWh]'])\n",
    "\n",
    "marker_edge_width = 0.7\n",
    "marker_alpha = 0.9\n",
    "bbox = dict(boxstyle=\"round\", pad=0.15, facecolor='none', edgecolor='none')\n",
    "annotation_shrink = 0.03\n",
    "\n",
    "kwargs_ghg_intensity  =   {\n",
    "    'edgecolor':'k',\n",
    "    #'marker': 'o',\n",
    "    'alpha': 0.05,\n",
    "    'linewidth':0.2,\n",
    "    'linestyle':'-',\n",
    "}\n",
    "custom_palette = [\"#FFFFFF\", \"#808080\", \"#000000\", \"#3A0CA3\", \"#4361EE\", \"#4CC9F0\"]\n",
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "sns.set_style('white')\n",
    "sns.set_context(\"paper\", font_scale = 1)\n",
    "sns.despine(right = True)\n",
    "sns.scatterplot(\n",
    "    x = 'HP Production [TWh/year]', y = 'GHG intensity [gCO<sub>2,eq</sub>/kWh]', \n",
    "    data = em_int_nondom_df, palette='Set2',\n",
    "    size='Firm Power Ratio, [%]', hue=\"Loss of Land [km<sup>2</sup>]\", sizes = (1,150),\n",
    "    #size=\"Loss of Land [km<sup>2</sup>]\", hue='Firm Power Ratio Cat', \n",
    "    #sizes = {'0-400 km2': 10, '400-800 km2': 30, '800-1200 km2': 60, '1200-1600 km2': 120},\n",
    "    **kwargs_ghg_intensity)\n",
    "legend1 = plt.legend(loc=\"upper right\", fontsize='large', ncols=1)\n",
    "legend1.set_frame_on(False)\n",
    "updated_text = [\n",
    "    \"Loss of Land, [km$^2$]\",\n",
    "    \"$0-400$ km$^2$\",\n",
    "    \"$400-800$ km$^2$\",\n",
    "    \"$800-1200$ km$^2$\",\n",
    "    \"$1200-1600$ km$^2$\",\n",
    "    \"Firm Power Ratio, [%]\",\n",
    "    \"$15$\",\n",
    "    \"$30$\",\n",
    "    \"$45$\",\n",
    "    \"$60$\",\n",
    "    \"$75$\"\n",
    "]\n",
    "for ix, text in enumerate(updated_text):\n",
    "    legend1.get_texts()[ix].set_text(text)\n",
    "plt.axvline(\n",
    "    x=current_solution[0], color='grey', linestyle='--', linewidth=2,\n",
    "    label='Current mean annual power production, GWh/year')\n",
    "plt.text(current_solution[0]-8, 34, 'Current mean annual HP production', \n",
    "         rotation=90, va='center', ha='center', fontsize=12)\n",
    "\n",
    "# Plot chosen solution scenarios\n",
    "plt.plot(\n",
    "    current_solution[0], current_solution[1], \n",
    "    marker='*', markersize=17, color='yellow', markeredgecolor='k', \n",
    "    markeredgewidth=marker_edge_width, alpha=marker_alpha)\n",
    "plt.annotate('$I_{b}$', xy=(current_solution[0], current_solution[1]), \n",
    "             xytext=(current_solution[0] + 20, current_solution[1] - 7.5),\n",
    "             arrowprops=dict(facecolor='black', shrink=annotation_shrink, width=2, headwidth = 8 ),\n",
    "             fontsize=14, bbox=bbox)\n",
    "# Current not built\n",
    "curr_nbuilt_x, curr_nbuilt_y = get_x_y_intensity_plot(notbuilt_current)\n",
    "plt.annotate('$I_{nb}$', xy=(curr_nbuilt_x, curr_nbuilt_y), xytext=(curr_nbuilt_x + 13, curr_nbuilt_y + 10),\n",
    "             arrowprops=dict(facecolor='black', shrink=annotation_shrink, width=2, headwidth = 8 ),\n",
    "             fontsize=14, bbox=bbox)\n",
    "plt.plot(\n",
    "    curr_nbuilt_x, curr_nbuilt_y, \n",
    "    marker='o', markersize=12, color='white', markeredgecolor='k', \n",
    "    markeredgewidth=marker_edge_width, alpha=marker_alpha)\n",
    "# Other values\n",
    "built_100_x, built_100_y = get_x_y_intensity_plot(built_100)\n",
    "plt.plot(\n",
    "    built_100_x, built_100_y, \n",
    "    marker='o', markersize=12, color='white', markeredgecolor='k', \n",
    "    markeredgewidth=marker_edge_width, alpha=marker_alpha)\n",
    "plt.annotate('$II_b$', xy=(built_100_x, built_100_y), xytext=(built_100_x + 20, built_100_y + 10),\n",
    "             arrowprops=dict(facecolor='black', shrink=annotation_shrink, width=2, headwidth = 8 ),\n",
    "             fontsize=14, bbox=bbox)\n",
    "notbuilt_100_x, notbuilt_100_y = get_x_y_intensity_plot(notbuilt_100)\n",
    "plt.plot(\n",
    "    notbuilt_100_x, notbuilt_100_y, \n",
    "    marker='o', markersize=12, color='white', markeredgecolor='k', \n",
    "    markeredgewidth=marker_edge_width, alpha=marker_alpha)\n",
    "plt.annotate('$II_{nb}$', xy=(notbuilt_100_x, notbuilt_100_y), xytext=(notbuilt_100_x + 38, notbuilt_100_y + 19),\n",
    "             arrowprops=dict(facecolor='black', shrink=annotation_shrink, width=2, headwidth = 8 ),\n",
    "             fontsize=14, bbox=bbox)\n",
    "built_200_x, built_200_y = get_x_y_intensity_plot(built_200)\n",
    "plt.plot(\n",
    "    built_200_x, built_200_y, \n",
    "    marker='o', markersize=12, color='white', markeredgecolor='k', \n",
    "    markeredgewidth=marker_edge_width, alpha=marker_alpha)\n",
    "plt.annotate('$III_{b}$', xy=(built_200_x, built_200_y), xytext=(built_200_x + 13, built_200_y + 10),\n",
    "             arrowprops=dict(facecolor='black', shrink=annotation_shrink, width=2, headwidth = 8 ),\n",
    "             fontsize=14, bbox=bbox)\n",
    "notbuilt_200_x, notbuilt_200_y = get_x_y_intensity_plot(notbuilt_200)\n",
    "plt.plot(\n",
    "    notbuilt_200_x, notbuilt_200_y, \n",
    "    marker='o', markersize=12, color='white', markeredgecolor='k', \n",
    "    markeredgewidth=marker_edge_width, alpha=marker_alpha)\n",
    "plt.annotate('$III_{nb}$', xy=(notbuilt_200_x, notbuilt_200_y), \n",
    "             xytext=(notbuilt_200_x + 25, notbuilt_200_y -7),\n",
    "             arrowprops=dict(facecolor='black', shrink=annotation_shrink, width=2, headwidth = 8 ),\n",
    "             fontsize=14, bbox=bbox)\n",
    "\n",
    "ax.tick_params(axis='x', labelsize=14)\n",
    "ax.tick_params(axis='y', labelsize=14)\n",
    "ax.set_ylim(-5,70)\n",
    "ax.set_xlim(0,250)\n",
    "plt.xlabel(\"HP Production, TWh/year\", fontsize=14)\n",
    "plt.ylabel(\"GHG intensity, gCO$_{2,eq}$/kWh\", fontsize=14)\n",
    "fig.savefig(pathlib.Path('figures/moo/GHG_intensity_HP_plot.png'), transparent=True, dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8694a9df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Plot\n",
    "def get_x_y_emissions_plot(data: pd.Series) -> Tuple[float, float]:\n",
    "    \"\"\" \"\"\"\n",
    "    return (\n",
    "        data['HP Production [TWh/year]'], \n",
    "        data['GHG emissions [tonne CO<sub>2,eq</sub>/year]'] / 1_000_000)\n",
    "\n",
    "merged_df['HP Production [TWh/year]'] = merged_df['HP Production [GWh/year]'] / 1_000\n",
    "merged_df['GHG emissions [Mt CO2/year]'] = \\\n",
    "    merged_df['GHG emissions [tonne CO<sub>2,eq</sub>/year]'] / 1_000_000\n",
    "em_int_nondom_df['GHG emissions [Mt CO2/year]'] = \\\n",
    "    em_int_nondom_df['GHG emissions [tonne CO<sub>2,eq</sub>/year]'] / 1_000_000\n",
    "\n",
    "kwargs  =   {\n",
    "    'edgecolor':'grey',\n",
    "    'marker': 'o',\n",
    "    'facecolor':'none',\n",
    "    'linewidth':0.01,\n",
    "    'linestyle':'-',\n",
    "    'alpha': 0.4\n",
    "}\n",
    "kwargs_nondom  =   {\n",
    "    'edgecolor':'k',\n",
    "    'marker': 'o',\n",
    "    'linewidth':0.05,\n",
    "    'linestyle':'-',\n",
    "    'alpha': 1\n",
    "}\n",
    "custom_palette = [\"#FFFFFF\", \"#808080\", \"#000000\", \"#3A0CA3\", \"#4361EE\", \"#4CC9F0\"]\n",
    "        \n",
    "fig, ax = plt.subplots(figsize=(8, 5), frameon=False, dpi=100)\n",
    "sns.set_style('white')\n",
    "sns.set_context(\"paper\", font_scale = 1)\n",
    "sns.despine(right = True)\n",
    "sns.scatterplot(\n",
    "    x = 'HP Production [TWh/year]', \n",
    "    y = 'GHG emissions [Mt CO2/year]', \n",
    "    data = merged_df, \n",
    "    #palette='Set2', #'YlOrRd', \n",
    "    #hue='Firm Power Ratio Cat',\n",
    "    s = 50,\n",
    "    **kwargs)\n",
    "\n",
    "ax.legend(title='Development scenario / Firm Energy, MW', fontsize=10, \n",
    "          title_fontsize=12, frameon=False,\n",
    "          ncol=3)\n",
    "\n",
    "sns.scatterplot(\n",
    "    x = 'HP Production [TWh/year]', y = 'GHG emissions [Mt CO2/year]', \n",
    "    data = em_int_nondom_df, palette='Set2',\n",
    "    size='Firm Power Ratio Cat', hue=\"Loss of Land [km<sup>2</sup>]\", \n",
    "    #sizes = {'0-400 km2': 10, '400-800 km2': 30, '800-1200 km2': 60, '1200-1600 km2': 120},\n",
    "    sizes = {'0%-25%': 10, '25%-50%': 50, '50%-75%': 100},\n",
    "    #sizes = (1,200),\n",
    "    **kwargs_nondom)\n",
    "\n",
    "legend2 = plt.legend(loc=\"upper left\", fontsize='large', bbox_to_anchor=(0.08, 1.05))\n",
    "legend2.set_frame_on(False)\n",
    "updated_text = [\n",
    "    \"Loss of Land, [km$^2$]\",\n",
    "    \"$0-400$ km$^2$\",\n",
    "    \"$400-800$ km$^2$\",\n",
    "    \"$800-1200$ km$^2$\",\n",
    "    \"$1200-1600$ km$^2$\",\n",
    "    \"Firm Power Ratio, [%]\",\n",
    "    \"$0\\% - 25\\%$\",\n",
    "    \"$25\\% - 50\\%$\",\n",
    "    \"$50\\% - 75\\%$\"\n",
    "]\n",
    "for ix, text in enumerate(updated_text):\n",
    "    legend2.get_texts()[ix].set_text(text)\n",
    "\n",
    "# Plot solution pointss\n",
    "current_solution = (\n",
    "    built_min['HP Production [GWh/year]']/1_000, \n",
    "    built_min['GHG emissions [tonne CO<sub>2,eq</sub>/year]']/1_000/1_000)\n",
    "plt.plot(\n",
    "    current_solution[0], current_solution[1], \n",
    "    marker='*', markersize=17, color='yellow', markeredgecolor='k', \n",
    "    markeredgewidth=marker_edge_width, alpha=marker_alpha)\n",
    "plt.annotate('$I_{b}$', xy=(current_solution[0], current_solution[1]), \n",
    "             xytext=(current_solution[0] + 10, current_solution[1] + 0.7),\n",
    "             arrowprops=dict(facecolor='black', shrink=annotation_shrink, width=2, headwidth = 8 ),\n",
    "             fontsize=14, bbox=bbox)\n",
    "# Current not built\n",
    "curr_nbuilt_x, curr_nbuilt_y = get_x_y_emissions_plot(notbuilt_current)\n",
    "plt.plot(\n",
    "    curr_nbuilt_x, curr_nbuilt_y, \n",
    "    marker='o', markersize=12, color='white', markeredgecolor='k', \n",
    "    markeredgewidth=marker_edge_width, alpha=marker_alpha)\n",
    "plt.annotate('$I_{nb}$', xy=(curr_nbuilt_x, curr_nbuilt_y), xytext=(curr_nbuilt_x + 25, curr_nbuilt_y + 1.5),\n",
    "             arrowprops=dict(facecolor='black', shrink=annotation_shrink, width=2, headwidth = 8 ),\n",
    "             fontsize=14, bbox=bbox)\n",
    "# Other values\n",
    "built_100_x, built_100_y = get_x_y_emissions_plot(built_100)\n",
    "plt.plot(\n",
    "    built_100_x, built_100_y, \n",
    "    marker='o', markersize=12, color='white', markeredgecolor='k', \n",
    "    markeredgewidth=marker_edge_width, alpha=marker_alpha)\n",
    "plt.annotate('$II_b$', xy=(built_100_x, built_100_y), xytext=(built_100_x + 15, built_100_y + 0.55),\n",
    "             arrowprops=dict(facecolor='black', shrink=annotation_shrink, width=2, headwidth = 8 ),\n",
    "             fontsize=14, bbox=bbox)\n",
    "notbuilt_100_x, notbuilt_100_y = get_x_y_emissions_plot(notbuilt_100)\n",
    "plt.plot(\n",
    "    notbuilt_100_x, notbuilt_100_y, \n",
    "    marker='o', markersize=12, color='white', markeredgecolor='k', \n",
    "    markeredgewidth=marker_edge_width, alpha=marker_alpha)\n",
    "plt.annotate('$II_{nb}$', xy=(notbuilt_100_x, notbuilt_100_y), xytext=(notbuilt_100_x + 30, notbuilt_100_y + 1.6),\n",
    "             arrowprops=dict(facecolor='black', shrink=annotation_shrink, width=2, headwidth = 8 ),\n",
    "             fontsize=14, bbox=bbox)\n",
    "built_200_x, built_200_y = get_x_y_emissions_plot(built_200)\n",
    "plt.plot(\n",
    "    built_200_x, built_200_y, \n",
    "    marker='o', markersize=12, color='white', markeredgecolor='k', \n",
    "    markeredgewidth=marker_edge_width, alpha=marker_alpha)\n",
    "plt.annotate('$III_{b}$', xy=(built_200_x, built_200_y), xytext=(built_200_x - 15, built_200_y + 0.7),\n",
    "             arrowprops=dict(facecolor='black', shrink=annotation_shrink, width=2, headwidth = 8 ),\n",
    "             fontsize=14, bbox=bbox)\n",
    "notbuilt_200_x, notbuilt_200_y = get_x_y_emissions_plot(notbuilt_200)\n",
    "plt.plot(\n",
    "    notbuilt_200_x, notbuilt_200_y, \n",
    "    marker='o', markersize=12, color='white', markeredgecolor='k', \n",
    "    markeredgewidth=marker_edge_width, alpha=marker_alpha)\n",
    "plt.annotate('$III_{nb}$', xy=(notbuilt_200_x, notbuilt_200_y), \n",
    "             xytext=(notbuilt_200_x + 23, notbuilt_200_y -0.25),\n",
    "             arrowprops=dict(facecolor='black', shrink=annotation_shrink, width=2, headwidth = 8 ),\n",
    "             fontsize=14, bbox=bbox) \n",
    "\n",
    "# Add vertical line denoting the current HP production\n",
    "plt.axvline(\n",
    "    x=current_solution[0], color='grey', linestyle='--', linewidth=2,\n",
    "    label='Current mean annual power production, GWh/year')\n",
    "plt.text(current_solution[0]-8, 2.5, 'Current mean annual HP production', \n",
    "         rotation=90, va='center', ha='center', fontsize=12)\n",
    "\n",
    "arrow_x = current_solution[0] + 20\n",
    "arrow_y_start = 0  # y-coordinate for the starting point of the arrow\n",
    "arrow_y_end = 0.95  # y-coordinate for the ending point of the arrow\n",
    "arrow_text = 'Forgone opportunity'  # Text to be displayed next to the arrow\n",
    "# Plot the line with arrows\n",
    "plt.annotate('', xy=(arrow_x, arrow_y_end), xytext=(arrow_x, arrow_y_start),\n",
    "             arrowprops=dict(arrowstyle='<->', color='k', lw=1.5), annotation_clip=False)\n",
    "# Add text annotation next to the arrow\n",
    "plt.text(arrow_x + 3, (arrow_y_start + arrow_y_end) / 2 - 0.05, arrow_text, color='k', fontsize=12)\n",
    "\n",
    "ax.tick_params(axis='x', labelsize=14)\n",
    "ax.tick_params(axis='y', labelsize=14)\n",
    "ax.set_ylim(-0.2,5)\n",
    "ax.set_xlim(0,250)\n",
    "plt.xlabel(\"HP Production, TWh/year\", fontsize=14)\n",
    "plt.ylabel(\"GHG Emissions, Mt CO$_2$ / annum\", fontsize=14)\n",
    "fig.savefig(pathlib.Path('figures/moo/GHG_emissions_HP_plot.png'), transparent=True, dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ad29cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct a dictionary with scenarios as keys and sets of constructed dams as values\n",
    "def map_ids_to_ifc(scenario_ids: Dict[str, Set[int]], id_map = id_ifc_map) -> Dict[str, List[int]]:\n",
    "    \"\"\" \"\"\"\n",
    "    return {key : list(set_remap(optim_ids, id_ifc_map)) for key, optim_ids in scenario_ids.items()}\n",
    "\n",
    "sc_dams: Dict[str, Set[int]] = map_ids_to_ifc({\n",
    "    \"Ib\": built_min['Dam IDs'],\n",
    "    \"Inb\": notbuilt_current['Dam IDs'],\n",
    "    \"IIb\": built_100['Dam IDs'],\n",
    "    \"IInb\": notbuilt_100['Dam IDs'],\n",
    "    \"IIIb\": built_200['Dam IDs'],\n",
    "    \"IIInb\": notbuilt_200['Dam IDs']\n",
    "})\n",
    "with open(pathlib.Path('intermediate/optim_scenarios.json'), 'w') as file:  \n",
    "    json_string = json.dumps(sc_dams, indent=4)\n",
    "    file.write(json_string)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5e765e28",
   "metadata": {},
   "source": [
    "# TODO: Add labels\n",
    "labels (dict with str keys and str values (default {})) â€“ By default, column names are used in the figure for axis titles, legend entries and hovers. This parameter allows this to be overridden. The keys of this dict should correspond to column names, and the values should correspond to the desired label to be displayed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c780ff20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This only works if previous figures have not been created\n",
    "merged_df['GHG emissions<br>[Mt CO2,eq/year]'] = \\\n",
    "    merged_df['GHG emissions [tonne CO<sub>2,eq</sub>/year]']/1000_000\n",
    "merged_df.rename(columns={\n",
    "    'Agricultural land loss, [km<sup>2</sup>]' : 'Agricultural land<br>loss, [km2]',\n",
    "    'Deforestation, [km<sup>2</sup>]' : 'Deforestation<br>[km2]',\n",
    "    'Land loss, [km<sup>2</sup>]' : 'Land loss<br>[km2]',\n",
    "    'GHG intensity [gCO<sub>2,eq</sub>/kWh]' : 'GHG intensity<br>[gCO2,eq/kWh]',\n",
    "    'Mean HP [GWh/d]' : 'Mean HP<br>[GWh/d]',\n",
    "    'Firm HP [GWh/d]' : 'Firm HP<br>[GWh/d]'\n",
    "}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39042bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df['Scenario, [1/0]'] = merged_df['Scenario, [1/0]'].astype('float')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8e2336d1",
   "metadata": {},
   "source": [
    "merged_df.rename(columns={\n",
    "    'Land loss, [km2]' : 'Land loss<br>[km2]'\n",
    "}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d60ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(merged_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850c9856",
   "metadata": {},
   "outputs": [],
   "source": [
    "mya_nobuilt_vis = OutputVisualiser(merged_df) #merged_df)\n",
    "fig = mya_nobuilt_vis.plot_parallel(\n",
    "    columns = (\n",
    "        'Mean HP<br>[GWh/d]', \n",
    "        'Firm HP<br>[GWh/d]', \n",
    "        'GHG emissions<br>[Mt CO2,eq/year]',\n",
    "        'Agricultural land<br>loss, [km2]', \n",
    "        'Deforestation<br>[km2]', \n",
    "        'Land loss<br>[km2]', \n",
    "        'GHG intensity<br>[gCO2,eq/kWh]',\n",
    "        'Firm Power Ratio, [%]',\n",
    "        'Scenario, [1/0]'), \n",
    "    labels = {\n",
    "        'Mean HP<br>[GWh/d]' : 'Mean HP',\n",
    "        'Firm HP<br>[GWh/d]' : 'Firm HP',\n",
    "        'GHG emissions<br>[Mt CO2,eq/year]': 'GHG emissions',\n",
    "        'Agricultural land<br>loss, [km2]' : 'Agricultural land loss',\n",
    "        'Deforestation<br>[km2]' : 'Deforestation',\n",
    "        'Land loss<br>[km2]' : 'Land loss',\n",
    "        'GHG intensity<br>[gCO2,eq/kWh]' : 'GHG intensity',\n",
    "        'Firm Power Ratio, [%]' : 'Firm power ratio',\n",
    "        'Scenario, [1/0]' : 'Scenario, [1/0]'\n",
    "    },\n",
    "    color_col = 'GHG intensity<br>[gCO2,eq/kWh]', color_limits=(0,60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4996f7cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_html_path=r\"figures/moo/parallel_plot.html\"\n",
    "input_template_path = r\"figures/moo/parallel_plot_template.html\"\n",
    "\n",
    "plotly_jinja_data = {\"fig\":fig.to_html(full_html=False)}\n",
    "#consider also defining the include_plotlyjs parameter to point to an external Plotly.js as described above\n",
    "\n",
    "with open(output_html_path, \"w\", encoding=\"utf-8\") as output_file:\n",
    "    with open(input_template_path) as template_file:\n",
    "        j2_template = Template(template_file.read())\n",
    "        output_file.write(j2_template.render(plotly_jinja_data))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
