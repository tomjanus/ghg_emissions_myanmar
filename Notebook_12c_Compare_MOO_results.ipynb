{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0fbab6f6",
   "metadata": {},
   "source": [
    "## Compare the sets of dams selected by MOO algorithm with emissions objective calculated from emission factors against the solutions of MOO runs where GHG emissions had been calculated explicitly with ReEmission (G-res methodology)\n",
    "## T. Janus\n",
    "### Created: 11/11/2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c9311be-8a0a-4281-938c-8f65feeba16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Set, Any, Optional, Dict\n",
    "from matplotlib.legend_handler import HandlerBase\n",
    "from string import Template\n",
    "import math\n",
    "import pathlib\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import jaccard_score\n",
    "from scipy.spatial import distance\n",
    "from lib.notebook12 import ObjectiveCalculator, set_remap\n",
    "\n",
    "# Load the mapping between ids used in the MOO algorithm and the IDs in the IFC database\n",
    "map_file_path = pathlib.Path('outputs/moo/id_to_ifc.json')\n",
    "# Some repetition here, but left for now in fear of breaking the code\n",
    "with open(map_file_path, 'r') as file:\n",
    "    id_map = json.load(file)\n",
    "id_map: Dict[int, int] = {int(key): value for key, value in id_map.copy().items()} # Maps optim ids to ifc ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1135683c",
   "metadata": {},
   "source": [
    "## Implemented indices\n",
    "### Average Jaccard Index\n",
    "\n",
    "Fo any two collections of sets, $A=\\{A_1,A_2,\\ldots,A_n\\}$ and $B=\\{B_1,B_2\\ldots,B_m\\}$ the average Jaccard index is calculated as:\n",
    "\n",
    "\\begin{equation}\n",
    "\\bar{J}(A,B) = \\frac{1}{n \\times m} \\sum_{i=1}^n \\sum_{j=1}^m J(A_i, B_j)\n",
    "\\end{equation}\n",
    "\n",
    "where $J(A_i, B_j)$ is the Jaccard index between sets $A_i$ and $B_j$ and is defined as\n",
    "\n",
    "\\begin{equation}\n",
    "J(A_i, B_j) =  = \\frac{|A_i \\cap B_j|}{|A_i \\cup B_j|}\n",
    "\\end{equation}\n",
    "\n",
    "where $\\left|A_i \\cap B_j \\right|$ is the cardinality of the intersection of sets $A_i$ and $B_j$, and $\\left|A_i \\cup B_j\\right|$ is the cardinality of the union of sets $A_i$ and $B_j$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6988c72f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "# Write statistics and comparison figures\n",
    "def num_sets(dam_sets: Dict[int, Dict[str, List[Set[int]]]], bin_index: int, scenario: str):\n",
    "    return len(dam_sets[bin_index][scenario])\n",
    "\n",
    "def convert_to_set(dam_ids: str) -> Set[int]:\n",
    "    # Remove curly braces and split the string by commas, then convert to integers\n",
    "    dam_ids = dam_ids.strip('{}').split(', ')\n",
    "    return set(map(int, dam_ids))\n",
    "\n",
    "# Define similarity metrics\n",
    "def cosine_similarity(vec1: List[float], vec2: List[float], verbose: bool = False) -> float:\n",
    "    \"\"\" \n",
    "    Calculates cosine similarity between two vectors: vec1 and vec2\n",
    "    Returns the cosine of the angle between two vectors (value between -1 and 1)\n",
    "    \"\"\"\n",
    "    A = np.array(vec1)\n",
    "    B = np.array(vect)\n",
    "    cosine = np.dot(A,B)/(norm(A)*norm(B))\n",
    "    if verbose:\n",
    "        print(\"Cosine Similarity:\", cosine)\n",
    "    return cosine\n",
    "\n",
    "def jaccard_similarity(set1: Set[Any], set2: Set[Any], verbose: bool = False) -> float:\n",
    "    \"\"\" \"\"\"\n",
    "    # intersection of two sets\n",
    "    intersection = set1.intersection(set2)\n",
    "    # Unions of two sets\n",
    "    union = set1.union(set2)\n",
    "    return len(intersection) / len(union)\n",
    "\n",
    "def average_jaccard_index(collection1, collection2, **kwargs):\n",
    "    similarities = []\n",
    "    for set1 in collection1:\n",
    "        for set2 in collection2:\n",
    "            similarities.append(jaccard_similarity(set1, set2, **kwargs))\n",
    "    return np.mean(similarities)\n",
    "\n",
    "\n",
    "def jaccard_distance(set1: Set[Any], set2: Set[Any], verbose: bool = False) -> float:\n",
    "    \"\"\" \"\"\"\n",
    "    #Symmetric difference of two sets\n",
    "    symmetric_difference = set1.symmetric_difference(set2)\n",
    "    # Unions of two sets\n",
    "    union = set1.union(set2)\n",
    "    return len(symmetric_difference)/len(union)\n",
    "\n",
    "def jaccard_score(y_true: np.ndarray, y_pred: np.ndarray, *args, **kwargs) -> np.double:\n",
    "    \"\"\" \"\"\"\n",
    "    return jaccard_score(y_true, y_pred, *args, **kwargs)\n",
    "\n",
    "def hamming_distance(u: 'np.typing.ArrayLike', v: 'np.typing.ArrayLike', w: Optional['np.typing.ArrayLike'] = None) -> np.double:\n",
    "    \"\"\" \"\"\"\n",
    "    return distance.hamming(u, v, w)\n",
    "\n",
    "def find_closest_row(df: pd.DataFrame, target_value: Any, column: str) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Returns the row where the 'value' column is closest to target_value.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        The DataFrame to search.\n",
    "    target_value : float\n",
    "        The value to find the closest match for.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    pd.Series\n",
    "        The row where 'value' is closest to target_value.\n",
    "    \"\"\"\n",
    "    closest_index = (df[column] - target_value).abs().idxmin()\n",
    "    return df.loc[closest_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc4c186",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set paths\n",
    "# Paths to output files from the algorithm with expansion / compression\n",
    "sol_file_folder_5obj = pathlib.Path('moo_solver_CPAIOR/outputs/epsilon2_5obj')\n",
    "sol_file_folder_3obj = pathlib.Path('moo_solver_CPAIOR/outputs/epsilon2_3obj_soued')\n",
    "options = {\n",
    "    '5obj' : {\n",
    "        'merged_csv_file': sol_file_folder_5obj / pathlib.Path('merged_df_5obj.csv'),\n",
    "        'nondom_csv_file': sol_file_folder_5obj / pathlib.Path('em_int_nondom_df_5obj.csv'),\n",
    "    },\n",
    "    '5obj_soued': {\n",
    "        'merged_csv_file': sol_file_folder_5obj / pathlib.Path('merged_df_5obj_soued.csv'),\n",
    "        'nondom_csv_file': sol_file_folder_5obj / pathlib.Path('em_int_nondom_df_5obj_soued.csv'),\n",
    "    },\n",
    "    '3obj_soued' : {\n",
    "        'merged_csv_file': sol_file_folder_3obj / pathlib.Path('merged_df_3obj_soued.csv'),\n",
    "        'nondom_csv_file': sol_file_folder_3obj / pathlib.Path('em_int_nondom_df_3obj_soued.csv'),\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd7cc3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "scale_column = 'HP Production [GWh/year]'\n",
    "optim_names = ['5obj', '5obj_soued']\n",
    "n_bins = 2000\n",
    "data = dict()\n",
    "for optim_name in optim_names:\n",
    "    data[optim_name] = dict()\n",
    "    df = pd.read_csv(options[optim_name]['nondom_csv_file'])\n",
    "    df[\"Dam IDs\"] = df[\"Dam IDs\"].apply(convert_to_set)\n",
    "    data[optim_name]['Built'] = df.query('Scenario == \"Built\"')\n",
    "    data[optim_name]['Not Built'] = df.query('Scenario == \"Not Built\"')\n",
    "    data[optim_name]['min_built'] = data[optim_name]['Built'][scale_column].min()\n",
    "    data[optim_name]['max_built'] = data[optim_name]['Built'][scale_column].max()\n",
    "    data[optim_name]['min_not_built'] = data[optim_name]['Not Built'][scale_column].min()\n",
    "    data[optim_name]['max_not_built'] = data[optim_name]['Not Built'][scale_column].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c7e602",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find min and max values and bin data\n",
    "min_built = min(\n",
    "    [data[optim_name]['Built'][scale_column].min() for optim_name in optim_names]\n",
    ")\n",
    "max_built = max(\n",
    "    [data[optim_name]['Built'][scale_column].max() for optim_name in optim_names]\n",
    ")\n",
    "min_not_built = min(\n",
    "    [data[optim_name]['Not Built'][scale_column].min() for optim_name in optim_names]\n",
    ")\n",
    "max_not_built = max(\n",
    "    [data[optim_name]['Not Built'][scale_column].max() for optim_name in optim_names]\n",
    ")\n",
    "bins_built = np.linspace(min_built, max_built, n_bins + 1)  # (n_bins + 1) edges create n_bins bins\n",
    "bins_not_built = np.linspace(min_not_built, max_not_built, n_bins + 1)  # (n_bins + 1) edges create n_bins bins\n",
    "\n",
    "# Calculate ranges for each bin\n",
    "bin_ranges_built = [\n",
    "    (int(bins_built[i]), int(bins_built[i+1])) for i in range(len(bins_built) - 1)\n",
    "]\n",
    "mean_gen_built = list(map(np.mean, bin_ranges_built))\n",
    "bin_ranges_not_built = [\n",
    "    (int(bins_not_built[i]), int(bins_not_built[i+1])) for i in range(len(bins_not_built) - 1)\n",
    "]\n",
    "mean_gen_not_built = list(map(np.mean, bin_ranges_not_built))\n",
    "for optim_name in optim_names:\n",
    "    data[optim_name]['Built']['bin'] = np.digitize(data[optim_name]['Built'][scale_column], bins_built) - 1\n",
    "    data[optim_name]['Not Built']['bin'] = np.digitize(data[optim_name]['Not Built'][scale_column], bins_not_built) - 1\n",
    "    data[optim_name]['Built'].at[-1, 'bin'] = int(n_bins - 1)\n",
    "    data[optim_name]['Not Built'].at[-1, 'bin'] = int(n_bins - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b9faba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "differences = map(lambda x: x[1] - x[0], bin_ranges_not_built)\n",
    "mean_difference = reduce(lambda acc, x: acc + x, differences) / len(bin_ranges_not_built)\n",
    "mean_difference\n",
    "bin_ranges_not_built[0][0] / 1_000, bin_ranges_not_built[-1][1] / 1_000\n",
    "bin_ranges_built[0][0] / 1_000, bin_ranges_built[-1][1] / 1_000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34667be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"HP Production bins of width {mean_difference / 1_000} TWh/year\")\n",
    "print(\n",
    "    f\"Production targets: {bin_ranges_not_built[0][0] / 1_000} \" +\n",
    "    f\"({bin_ranges_built[0][0] / 1_000} in case of built scenario) \" +\n",
    "    f\"up to {bin_ranges_not_built[-1][1] / 1_000} TWh/year\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d99475",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inalize data structures for storing binned data\n",
    "dam_sets_in_bins_built = {\n",
    "    i: {optim_name: [] for optim_name in optim_names} for i in range(n_bins)}  # `n_bins` bins\n",
    "dam_sets_in_bins_not_built = {\n",
    "    i: {optim_name: [] for optim_name in optim_names} for i in range(n_bins)}  # `n_bins` bins\n",
    "# For built dam optimization scenario\n",
    "for optim_name in optim_names:\n",
    "    data_sel = data[optim_name]['Built']\n",
    "    for bin_num in range(n_bins):\n",
    "        row_indices = data_sel.index[data_sel['bin']==bin_num].tolist()\n",
    "        dam_sets = [data_sel.loc[index, \"Dam IDs\"] for index in row_indices]\n",
    "        dam_sets_cleaned = [x for x in dam_sets if isinstance(x,set)]\n",
    "        dam_sets_in_bins_built[bin_num][optim_name] = dam_sets_cleaned\n",
    "# For not built dam optimization scenario\n",
    "for optim_name in optim_names:\n",
    "    data_sel = data[optim_name]['Not Built']\n",
    "    for bin_num in range(n_bins):\n",
    "        row_indices = data_sel.index[data_sel['bin']==bin_num].tolist()\n",
    "        dam_sets = [data_sel.loc[index, \"Dam IDs\"] for index in row_indices]\n",
    "        dam_sets_cleaned = [x for x in dam_sets if isinstance(x,set)]\n",
    "        dam_sets_in_bins_not_built[bin_num][optim_name] = dam_sets_cleaned"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf20adaf",
   "metadata": {},
   "source": [
    "## Calculate average Jaccard indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec8207e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Not built\n",
    "ave_jaccard_sim_not_built = {}\n",
    "for bin_index in range(n_bins):\n",
    "    sets_5obj = dam_sets_in_bins_not_built[bin_index]['5obj']\n",
    "    sets_5obj_soued = dam_sets_in_bins_not_built[bin_index]['5obj_soued']\n",
    "    num_sets1 = num_sets(dam_sets = dam_sets_in_bins_built, bin_index=bin_index, scenario='5obj')\n",
    "    num_sets2 = num_sets(dam_sets = dam_sets_in_bins_built, bin_index=bin_index, scenario='5obj_soued')\n",
    "    ave_jaccard_sim_not_built[bin_index] = [mean_gen_not_built[bin_index], average_jaccard_index(sets_5obj, sets_5obj_soued)]\n",
    "# 2. Built\n",
    "ave_jaccard_sim_built = {}\n",
    "for bin_index in range(n_bins):\n",
    "    sets_5obj = dam_sets_in_bins_built[bin_index]['5obj']\n",
    "    sets_5obj_soued = dam_sets_in_bins_built[bin_index]['5obj_soued']\n",
    "    num_sets1 = num_sets(dam_sets = dam_sets_in_bins_built, bin_index=bin_index, scenario='5obj')\n",
    "    num_sets2 = num_sets(dam_sets = dam_sets_in_bins_built, bin_index=bin_index, scenario='5obj_soued')\n",
    "    ave_jaccard_sim_built[bin_index] = [mean_gen_built[bin_index], average_jaccard_index(sets_5obj, sets_5obj_soued)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e6904e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ave_jacard_df_built = pd.DataFrame.from_dict(ave_jaccard_sim_built, orient='index').\\\n",
    "    rename(columns={0:\"HP Production [GWh/year]\", 1: \"Mean Jaccard Index\"}).\\\n",
    "    assign(Status = \"Built\")\n",
    "ave_jacard_df_not_built = pd.DataFrame.from_dict(ave_jaccard_sim_not_built, orient='index').\\\n",
    "    rename(columns={0:\"HP Production [GWh/year]\", 1: \"Mean Jaccard Index\"}).\\\n",
    "    assign(Status = \"Not Built\")\n",
    "ave_jacard_df = pd.concat([ave_jacard_df_built, ave_jacard_df_not_built])\n",
    "ave_jacard_df[\"HP Production [TWh/year]\"] = ave_jacard_df[\"HP Production [GWh/year]\"] / 1_000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ca5efb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "min_prod_target = ave_jacard_df_built.iloc[0]['HP Production [GWh/year]']\n",
    "max_prod_target = ave_jacard_df_built.iloc[-1]['HP Production [GWh/year]']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aebf031b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ave_jacard_df.query(\n",
    "    '`Mean Jaccard Index` < 0.78 & Status == \"Not Built\" & `HP Production [TWh/year]` >41' +\n",
    "    ' & `HP Production [TWh/year]` < 43')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "273edfb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ave_jacard_df.query('`Mean Jaccard Index` < 0.75 & Status == \"Built\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ea4ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ave_jacard_df.query(\n",
    "    '`Mean Jaccard Index` < 0.75 & Status == \"Not Built\" & `HP Production [TWh/year]` > 160')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5bc637e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ave_jacard_df.query(\n",
    "    'Status == \"Not Built\" & `HP Production [TWh/year]` > 50')[\"Mean Jaccard Index\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a6802b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ave_jacard_df.query(\n",
    "    'Status == \"Built\" & `HP Production [TWh/year]` > 50')[\"Mean Jaccard Index\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf48bab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "optim_outputs = dict()\n",
    "for optim_name in optim_names:\n",
    "    optim_outputs[optim_name] = pd.read_csv(options[optim_name]['nondom_csv_file'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f5b1ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ave_jacard_df.query('Status == \"Built\"').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc2e3ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick data (row locations) manually - These rows contain production targets that are also picked in\n",
    "# Notebook_12b, i.e. the notebook that selects optimization scenarios for visualisation and comparison\n",
    "target_1a_loc = 948 # 114.90 TWh/year (Not Built)\n",
    "target_1b_loc = 346 # 42 TWh/year (Not Built)\n",
    "target_2a_loc = 1188 # 150.4 TWh/year (Built)\n",
    "target_2b_loc = 1690 # 204.76 TWh/year (Not Built)\n",
    "sc2_option = (\"b\", \"a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "752445d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick HP Production targets - automatically pick sc2_option[0] == \"b\"\n",
    "target_1_nb = ave_jacard_df.query('Status == \"Not Built\"').loc[target_1b_loc]\n",
    "target_1_nb_value = target_1_nb['HP Production [TWh/year]']\n",
    "target_1_nb_mji = target_1_nb['Mean Jaccard Index']\n",
    "# Find emissions\n",
    "target_1_nb_em_gres = find_closest_row(\n",
    "    df = optim_outputs['5obj'].query('Scenario == \"Not Built\"'),\n",
    "    target_value = target_1_nb_value * 1_000,\n",
    "    column = 'HP Production [GWh/year]'\n",
    ")['GHG emissions [tonne CO<sub>2,eq</sub>/year]']/1000_000\n",
    "target_1_nb_em_soued = find_closest_row(\n",
    "    df = optim_outputs['5obj_soued'].query('Scenario == \"Not Built\"'),\n",
    "    target_value = target_1_nb_value * 1_000,\n",
    "    column = 'HP Production [GWh/year]'\n",
    ")['GHG emissions [tonne CO<sub>2,eq</sub>/year]']/1000_000\n",
    "\n",
    "target_1_b = find_closest_row(\n",
    "    df = ave_jacard_df.query('Status == \"Built\"'), \n",
    "    target_value = target_1_nb_value, \n",
    "    column = 'HP Production [TWh/year]')\n",
    "target_1_b_value = target_1_b['HP Production [TWh/year]']\n",
    "target_1_b_mji = target_1_b['Mean Jaccard Index']\n",
    "# Find emissions\n",
    "target_1_b_em_gres = find_closest_row(\n",
    "    df = optim_outputs['5obj'].query('Scenario == \"Built\"'),\n",
    "    target_value = target_1_b_value * 1_000,\n",
    "    column = 'HP Production [GWh/year]'\n",
    ")['GHG emissions [tonne CO<sub>2,eq</sub>/year]']/1_000_000\n",
    "target_1_b_em_soued = find_closest_row(\n",
    "    df = optim_outputs['5obj_soued'].query('Scenario == \"Built\"'),\n",
    "    target_value = target_1_b_value * 1_000,\n",
    "    column = 'HP Production [GWh/year]'\n",
    ")['GHG emissions [tonne CO<sub>2,eq</sub>/year]']/1000_000\n",
    "\n",
    "#target_1_b_damids = target_1_b['Dam IDs']\n",
    "\n",
    "if sc2_option[1] == \"a\":\n",
    "    \n",
    "    target_2_b = ave_jacard_df.query('Status == \"Built\"').loc[target_2a_loc]\n",
    "    target_2_b_value = target_2_b['HP Production [TWh/year]']\n",
    "    target_2_b_mji = target_2_b['Mean Jaccard Index']\n",
    "    # Find emissions\n",
    "    target_2_b_em_gres = find_closest_row(\n",
    "        df = optim_outputs['5obj'].query('Scenario == \"Built\"'),\n",
    "        target_value = target_2_b_value * 1_000,\n",
    "        column = 'HP Production [GWh/year]'\n",
    "    )['GHG emissions [tonne CO<sub>2,eq</sub>/year]']/1000_000\n",
    "\n",
    "    target_2_b_em_soued = find_closest_row(\n",
    "        df = optim_outputs['5obj_soued'].query('Scenario == \"Built\"'),\n",
    "        target_value = target_2_b_value * 1_000,\n",
    "        column = 'HP Production [GWh/year]'\n",
    "    )['GHG emissions [tonne CO<sub>2,eq</sub>/year]']/1000_000\n",
    "\n",
    "    target_2_nb = find_closest_row(\n",
    "        df = ave_jacard_df.query('Status == \"Not Built\"'), \n",
    "        target_value = target_2_b_value, \n",
    "        column = 'HP Production [TWh/year]')\n",
    "    target_2_nb_value = target_2_nb['HP Production [TWh/year]']\n",
    "    target_2_nb_mji = target_2_nb['Mean Jaccard Index']\n",
    "    # Find emissions\n",
    "    target_2_nb_em_gres = find_closest_row(\n",
    "        df = optim_outputs['5obj'].query('Scenario == \"Not Built\"'),\n",
    "        target_value = target_2_nb_value * 1_000,\n",
    "        column = 'HP Production [GWh/year]'\n",
    "    )['GHG emissions [tonne CO<sub>2,eq</sub>/year]']/1000_000\n",
    "\n",
    "    target_2_nb_em_soued = find_closest_row(\n",
    "        df = optim_outputs['5obj_soued'].query('Scenario == \"Not Built\"'),\n",
    "        target_value = target_2_nb_value * 1_000,\n",
    "        column = 'HP Production [GWh/year]'\n",
    "    )['GHG emissions [tonne CO<sub>2,eq</sub>/year]']/1000_000\n",
    "    \n",
    "elif sc2_option[1] == \"b\":\n",
    "    target_2_nb = ave_jacard_df.query('Status == \"Not Built\"').loc[target_2b_loc]\n",
    "    target_2_nb_value = target_2_nb['HP Production [TWh/year]']\n",
    "    target_2_nb_mji = target_2_nb['Mean Jaccard Index']\n",
    "    # Find emissions\n",
    "    target_2_nb_em_gres = find_closest_row(\n",
    "        df = optim_outputs['5obj'].query('Scenario == \"Not Built\"'),\n",
    "        target_value = target_2_nb_value * 1_000,\n",
    "        column = 'HP Production [GWh/year]'\n",
    "    )['GHG emissions [tonne CO<sub>2,eq</sub>/year]']/1000_000\n",
    "    target_2_nb_em_soued = find_closest_row(\n",
    "        df = optim_outputs['5obj_soued'].query('Scenario == \"Not Built\"'),\n",
    "        target_value = target_2_nb_value * 1_000,\n",
    "        column = 'HP Production [GWh/year]'\n",
    "    )['GHG emissions [tonne CO<sub>2,eq</sub>/year]']/1000_000\n",
    "    \n",
    "    target_2_b = find_closest_row(\n",
    "        df = ave_jacard_df.query('Status == \"Built\"'), \n",
    "        target_value = target_2_nb_value, \n",
    "        column = 'HP Production [TWh/year]')\n",
    "    target_2_b_value = target_2_b['HP Production [TWh/year]']\n",
    "    target_2_b_mji = target_2_b['Mean Jaccard Index']\n",
    "    # Find emissions\n",
    "    target_2_b_em_gres = find_closest_row(\n",
    "        df = optim_outputs['5obj'].query('Scenario == \"Built\"'),\n",
    "        target_value = target_2_b_value * 1_000,\n",
    "        column = 'HP Production [GWh/year]'\n",
    "    )['GHG emissions [tonne CO<sub>2,eq</sub>/year]']/1000_000\n",
    "    target_2_b_em_soued = find_closest_row(\n",
    "        df = optim_outputs['5obj_soued'].query('Scenario == \"Built\"'),\n",
    "        target_value = target_2_b_value * 1_000,\n",
    "        column = 'HP Production [GWh/year]'\n",
    "    )['GHG emissions [tonne CO<sub>2,eq</sub>/year]']/1000_000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad37050",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find objective functions for each of the four selected points\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4922951",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CenteredTitleHandler(HandlerBase):\n",
    "    def create_artists(self, legend, orig_handle, xdescent, ydescent, width, height, fontsize, trans):\n",
    "        title = legend.get_title()\n",
    "        text = plt.text(0, 0, title.get_text(), \n",
    "                        ha=\"center\", va=\"center\", \n",
    "                        fontsize=title.get_fontsize())\n",
    "        return [text]\n",
    "    \n",
    "def create_figure_txt(jaccard_index, em_gres, em_ipcc) -> str:\n",
    "    template = Template(\n",
    "        \"Mean Jaccard Index: ${jaccard_index}\\n\"\n",
    "        \"Net Emission (G-res): ${em_gres}, MtCO$$_{2e}$$/year \\n\"\n",
    "        \"Net Emission (EF): ${em_ipcc}, MtCO$$_{2e}$$/year\"\n",
    "    )\n",
    "    return template.substitute(\n",
    "        jaccard_index=f\"{jaccard_index:.2f}\",\n",
    "        em_gres=f\"{em_gres:.2f}\",\n",
    "        em_ipcc=f\"{em_ipcc:.2f}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a1e2a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seaborn style for publication-quality plots\n",
    "sns.set(style=\"white\", context=\"talk\")\n",
    "# Initialize the plot\n",
    "fig = plt.figure(figsize=(10, 6))\n",
    "ax = plt.subplot(111)\n",
    "\n",
    "diverging_colors = sns.color_palette(\"RdBu\", 2)\n",
    "#sns.palplot(diverging_colors)\n",
    "#palette ='coolwarm'\n",
    "\n",
    "# Create scatter plot with hue based on 'Status'\n",
    "scatter = sns.scatterplot(\n",
    "    ax = ax,\n",
    "    data=ave_jacard_df,\n",
    "    x='HP Production [GWh/year]',\n",
    "    y='Mean Jaccard Index',\n",
    "    hue='Status',\n",
    "    palette=diverging_colors, #'tab10',    # Change palette for publication\n",
    "    s=100,              # Set marker size\n",
    "    alpha=0.7,\n",
    "    edgecolor=\"k\",      # Add edge color for markers\n",
    "    linewidth=0.5       # Thin edge line\n",
    ")\n",
    "sns.despine()\n",
    "\n",
    "# Format plot for publication\n",
    "ax.set_ylabel('Mean Jaccard Index', fontsize=14, color='#4f4e4e')\n",
    "\n",
    "# Set the main title\n",
    "plt.suptitle(\n",
    "    \"Similarity Between Optimal Reservoir Portfolios for Two GHG Emission Criteria\",  # Main title text\n",
    "    fontsize=13,  # Set the font size\n",
    "    color='#4f4e4e',  # Set the color\n",
    "    weight='bold',\n",
    "    x=0.51,  # Adjust this to align with the subtitle\n",
    "    y=0.93,  # Adjust this to align with the subtitle\n",
    ")\n",
    "ttl = ax.title\n",
    "# Set the subtitle\n",
    "ax.set_title(\n",
    "    \"Explicitly Derived Emissions (G-res Methodology) vs Emission Factors (EF)\",  # Subtitle text\n",
    "    fontsize=12,  # Set the font size\n",
    "    color='#4f4e4e',  # Set the color\n",
    ")\n",
    "# tweak the title\n",
    "ttl.set_weight('normal')\n",
    "ttl.set_color('#4f4e4e')\n",
    "\n",
    "# Customize legend\n",
    "plt.legend(title='Status', title_fontsize='13', fontsize='11', loc='best', \n",
    "           frameon=True,\n",
    "           handler_map={None: CenteredTitleHandler()})\n",
    "# Ensure tight layout and grid for better spacing\n",
    "plt.tight_layout()\n",
    "#plt.grid(True, linestyle=\"-\", alpha=0.3)\n",
    "\n",
    "# add more ticks\n",
    "# ax.set_xticks(np.arange(25))\n",
    "# remove tick marks\n",
    "ax.xaxis.set_tick_params(size=8, color='#4f4e4e')\n",
    "ax.yaxis.set_tick_params(size=8, color='#4f4e4e')\n",
    "\n",
    "# change the color of the top and right spines to opaque gray\n",
    "ax.spines['right'].set_color((.8,.8,.8))\n",
    "ax.spines['top'].set_color((.8,.8,.8))\n",
    "\n",
    "ax.set_xlim([0, 250_000])\n",
    "\n",
    "# tweak the axis labels\n",
    "xlab = ax.xaxis.get_label()\n",
    "ylab = ax.yaxis.get_label()\n",
    "\n",
    "# Get the handles and labels of the axis\n",
    "handles, labels = plt.gca().get_legend_handles_labels()\n",
    "\n",
    "plt.axvspan(\n",
    "    xmin=0,  # Set the start of the shaded region\n",
    "    xmax=45_000,  # Set the end of the shaded region\n",
    "    alpha=0.05,  # Set the transparency of the shaded region\n",
    "    color=\"grey\",  # Set the color of the shaded region\n",
    "    zorder=0,  # Put shaded region behind plot\n",
    ")\n",
    "ax.axvline(x=45_000, color='k', linestyle='-', alpha = 0.5, linewidth=0.5)\n",
    "\n",
    "# Add an arrow with text highlighting a built scenario, scenario I\n",
    "plt.annotate(\n",
    "    text=create_figure_txt(\n",
    "        jaccard_index=target_1_b_mji, \n",
    "        em_gres=target_1_b_em_gres, \n",
    "        em_ipcc=target_1_b_em_soued),  # Text for the annotation\n",
    "    xy=(target_1_b_value * 1_000, target_1_b_mji),  # x and y coordinates of the data point\n",
    "    xytext=(20_000, 0.90),  # x and y coordinates for the annotation text\n",
    "    color=\"#292828\",  # Color of the text\n",
    "    fontsize=9,  # Fontsize of the text\n",
    "    arrowprops={\"color\": \"black\", \"arrowstyle\": \"-\", \"linewidth\": 0.55},  # Settings for the arrow\n",
    "    # Adding a shaded, rounded rectangle around the text\n",
    "    bbox=dict(\n",
    "        boxstyle=\"round,pad=0.4\",     # Rounded box with padding\n",
    "        edgecolor=\"black\",            # Border color\n",
    "        facecolor=\"white\",        # Background color for the box\n",
    "        linewidth=0.3,                # Border line width\n",
    "        alpha=0.7                     # Transparency of the background\n",
    "    )\n",
    ")\n",
    "ax.plot(\n",
    "    target_1_b_value * 1_000, target_1_b_mji, \n",
    "    marker='o', markersize=13, markeredgecolor='black',\n",
    "    markerfacecolor=(1, 1, 1, 0.9),\n",
    "    markeredgewidth=1.0, alpha=0.8)\n",
    "# Add an arrow with text highlighting a not-built scenario, scenario I\n",
    "plt.annotate(\n",
    "    text=create_figure_txt(\n",
    "        jaccard_index=target_1_nb_mji,  \n",
    "        em_gres=target_1_nb_em_gres, \n",
    "        em_ipcc=target_1_nb_em_soued),  # Text for the annotation  # Text for the annotation\n",
    "    xy=(target_1_nb_value * 1_000, target_1_nb_mji),  # x and y coordinates of the data point\n",
    "    xytext=(32_000, 0.46),  # x and y coordinates for the annotation text\n",
    "    color=\"#292828\",  # Color of the text\n",
    "    fontsize=9,  # Fontsize of the text\n",
    "    arrowprops={\"color\": \"black\", \"arrowstyle\": \"-\", \"linewidth\": 0.55},  # Settings for the arrow\n",
    "    # Adding a shaded, rounded rectangle around the text\n",
    "    bbox=dict(\n",
    "        boxstyle=\"round,pad=0.4\",     # Rounded box with padding\n",
    "        edgecolor=\"black\",            # Border color\n",
    "        facecolor=\"white\",        # Background color for the box\n",
    "        linewidth=0.3,                # Border line width\n",
    "        alpha=0.7                     # Transparency of the background\n",
    "    )\n",
    ")\n",
    "ax.plot(\n",
    "    target_1_nb_value * 1_000, target_1_nb_mji, \n",
    "    marker='o', markersize=13, markeredgecolor='black',\n",
    "    markerfacecolor=(1, 1, 1, 0.9),\n",
    "    markeredgewidth=1.0, alpha=0.8)\n",
    "# Repeat the same for scenario II\n",
    "plt.annotate(\n",
    "    text=create_figure_txt(\n",
    "        jaccard_index=target_2_nb_mji, \n",
    "        em_gres=target_2_nb_em_gres, \n",
    "        em_ipcc=target_2_nb_em_soued),  # Text for the annotation  # Text for the annotation  # Text for the annotation\n",
    "    xy=(target_2_nb_value * 1_000, target_2_nb_mji),  # x and y coordinates of the data point\n",
    "    xytext=(160_000, 0.40),  # x and y coordinates for the annotation text\n",
    "    color=\"#292828\",  # Color of the text\n",
    "    fontsize=9,  # Fontsize of the text\n",
    "    arrowprops={\"color\": \"black\", \"arrowstyle\": \"-\", \"linewidth\": 0.55},  # Settings for the arrow\n",
    "    # Adding a shaded, rounded rectangle around the text\n",
    "    bbox=dict(\n",
    "        boxstyle=\"round,pad=0.4\",     # Rounded box with padding\n",
    "        edgecolor=\"black\",            # Border color\n",
    "        facecolor=\"white\",        # Background color for the box\n",
    "        linewidth=0.3,                # Border line width\n",
    "        alpha=0.7                     # Transparency of the background\n",
    "    )\n",
    ")\n",
    "ax.plot(\n",
    "    target_2_nb_value * 1_000, target_2_nb_mji, \n",
    "    marker='o', markersize=13, markeredgecolor='black',\n",
    "    markerfacecolor=(1, 1, 1, 0.9),\n",
    "    markeredgewidth=1.0, alpha=0.8)\n",
    "\n",
    "ax.annotate(\n",
    "    text=create_figure_txt(\n",
    "        jaccard_index=target_2_b_mji, \n",
    "        em_gres=target_2_b_em_gres, \n",
    "        em_ipcc=target_2_b_em_soued),  # Text for the annotation  # Text for the annotation  # Text for the annotation  # Text for the annotation\n",
    "    xy=(target_2_b_value * 1_000, target_2_b_mji),  # x and y coordinates of the data point\n",
    "    xytext=(60_000, 0.25),  # x and y coordinates for the annotation text\n",
    "    color=\"#292828\",  # Color of the text\n",
    "    fontsize=9,  # Fontsize of the text\n",
    "    arrowprops={\"color\": \"black\", \"arrowstyle\": \"-\", \"linewidth\": 0.55},  # Settings for the arrow\n",
    "    # Adding a shaded, rounded rectangle around the text\n",
    "    bbox=dict(\n",
    "        boxstyle=\"round,pad=0.4\",     # Rounded box with padding\n",
    "        edgecolor=\"black\",            # Border color\n",
    "        facecolor=\"white\",        # Background color for the box\n",
    "        linewidth=0.3,                # Border line width\n",
    "        alpha=0.7                     # Transparency of the background\n",
    "    )\n",
    ")\n",
    "ax.plot(\n",
    "    target_2_b_value * 1_000, target_2_b_mji, \n",
    "    marker='o', markersize=13, markeredgecolor='black',\n",
    "    markerfacecolor=(1, 1, 1, 0.9),\n",
    "    markeredgewidth=1.0, alpha=0.8)\n",
    "\n",
    "\n",
    "ax.axvline(x=min_prod_target, color='gray', linestyle='--', alpha = 0.5)\n",
    "ax.axvline(x=target_1_b_value * 1_000, color='gray', linestyle='--', alpha = 0.5)\n",
    "ax.axvline(x=target_2_b_value * 1_000, color='gray', linestyle='--', alpha = 0.5)\n",
    "ax.axvline(x=max_prod_target, color='gray', linestyle='--', alpha = 0.5)\n",
    "\n",
    "x_ticks = [50_000, 100_000, 150_000, 200_000, 250_000]\n",
    "new_labels = [\"50\", \"100\", \"150\", \"200\", \"250\"]  # New xtick labels\n",
    "plt.xticks(ticks=x_ticks, labels=new_labels, fontsize=16)\n",
    "plt.yticks(fontsize=16)\n",
    "ax.set_xlabel('HP Production [TWh/year]', fontsize=14, color='#4f4e4e')\n",
    "\n",
    "marker_edge_width = 0.7\n",
    "marker_alpha = 0.9\n",
    "ax.plot(\n",
    "    min_prod_target, 0.2, \n",
    "    marker='*', markersize=20, color='yellow', markeredgecolor='k', \n",
    "    markeredgewidth=marker_edge_width, alpha=marker_alpha)\n",
    "ax.plot(\n",
    "    max_prod_target, 0.2,\n",
    "    marker='d', markersize=16, color=\"yellow\", markeredgecolor='k', \n",
    "    markeredgewidth=marker_edge_width, alpha=marker_alpha)\n",
    "\n",
    "xlab.set_style('normal')\n",
    "xlab.set_size(16)\n",
    "ylab.set_style('normal')\n",
    "ylab.set_size(16)\n",
    "\n",
    "# Create the legend\n",
    "leg = plt.legend(\n",
    "    handles=handles,\n",
    "    title=\"Optimization Scenario\",  # Set a title for the legend\n",
    "    title_fontsize=14,  # Set the legend title size\n",
    "    fontsize=12,  # Set the fontsize of the legend labels\n",
    "    bbox_to_anchor=(0.93, 0.19),  # Customize the position of the legend here\n",
    "    frameon=False,  # Disable the legend border\n",
    "    facecolor='white', framealpha=1,\n",
    "    alignment = 'center',\n",
    "    ncol=2,\n",
    "    labels=[  # Customize the labels you want in the legend\n",
    "        \"Built\",\n",
    "        \"Not Built\",\n",
    "    ],\n",
    ")\n",
    "\n",
    "leg._legend_box.align = \"left\"\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b436d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_options = ['png', 'pdf', 'svg']\n",
    "fig_folder = pathlib.Path(\"outputs/figures/moo\")\n",
    "if 'png' in fig_options:  \n",
    "    fig.savefig(fig_folder / 'mean_jaccard.png', bbox_inches='tight', dpi=600, transparent=True)\n",
    "if 'pdf' in fig_options:\n",
    "    fig.savefig(fig_folder / 'mean_jaccard.pdf', bbox_inches='tight')\n",
    "if 'svg' in fig_options:\n",
    "    fig.savefig(fig_folder / 'mean_jaccard.svg', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25fc9660",
   "metadata": {},
   "source": [
    "### The End"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
