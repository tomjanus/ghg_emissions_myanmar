{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e8d6f02",
   "metadata": {},
   "source": [
    "# Reduce dimensionality of feature-space and feature-rank-space, find cluster and visualise the processed data\n",
    "## Works on SHAP values and breakdown interactions from DALEX\n",
    "## Author: Tomasz Janus, Mui Ne, 10/11/2023\n",
    "### email: tomasz.janus@manchester.ac.uk ; tomasz.k.janus@gmail.com\n",
    "\n",
    "The notebook is intended to import feature importances or SHAP values for either CO2 or CH4 emissions. Reduce dimensionality in the feature importance / shap space using PCA, then cluster the data using an algorithm of choice and visualise the clusters on pca reduced space, t-sne reduced space and on maps.\n",
    "\n",
    "Second, a rank matrix is developed in the feature importance / shap space which is used to cluster the data based on ranks using some similarity measure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec0112e1",
   "metadata": {},
   "source": [
    "## Flow-chart\n",
    "1. Import the feature importance dataset(s) for CO$_2$ and CH$_4$ emissions\n",
    "2. Import the input-output data from re-emission\n",
    "3. Find outliers in the feature-importance dataset(s)\n",
    "4. Scale the feature importance data\n",
    "5. Perform dimensionality reduction\n",
    "6. Cluster the data in old or new (only PCA allowed) coordinate system and visualise clusters in lower dimensional space\n",
    "7. Plot the clusters on maps\n",
    "\n",
    "### Dimensionality reduction(s) used: \n",
    "* PCA\n",
    "* FA\n",
    "* LDA (not implemented yet) - in ToDo's if time allows\n",
    "* t-SNE\n",
    "* UMAP\n",
    "* PCoA\n",
    "* NMDS\n",
    "\n",
    "### Clustering methods used: \n",
    "* K-Means\n",
    "* K-Medoids\n",
    "* DBScan\n",
    "* HDBScan\n",
    "* GMM (Gaussian Mixture Model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ac7a16",
   "metadata": {},
   "source": [
    "## General logic\n",
    "1. Find Clusters in data and present them on 2D plots and maps\n",
    "2. We have three types of data that can be used for clustering\n",
    "    * a) - Feature Importances\n",
    "    * b) - Ranking of features, e.g. which features plays importance in predicting output first\n",
    "    * c) - emission intensities - let's do this next by showing co2 and ch4 emission intensities as a pair\n",
    "    \n",
    "## Perform two different types of analyses for feature space and rank space\n",
    "    * Feature Space - Use K-Means, HDBSCAN, BGMM and OPTICS clustering algorithms\n",
    "    * Rank Space - Use K-Medoids, HDBSCAN, OPTICS, sklearn.cluster.AgglomerativeClustering\n",
    "    \n",
    "    * Feature Space - USE PCA, t-SNE, UMAP, NMDS, embeddings\n",
    "    * Rank Space - USE PCoA and NMDS embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc19e6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple, Dict, Literal, List, Sequence, Set, Callable\n",
    "import os\n",
    "import pathlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import dalex\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import mpl_toolkits.mplot3d  # noqa: F401\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "import plotly_express as px\n",
    "import plotly.graph_objs as go\n",
    "import chart_studio.plotly as py\n",
    "\n",
    "import sklearn\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, Normalizer, MinMaxScaler\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from umap import UMAP\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "\n",
    "import lib.dim_reduction as dr\n",
    "import lib.clustering as clust\n",
    "from lib.data_loaders import load_feature_importances, load_input_output\n",
    "from lib.ranks import (\n",
    "    get_ranks, plot_rank_heatmap, rank_distance_matrix, FeatureCorrelationMap, \n",
    "    exp_scaling_fun, rank_distance)\n",
    "from lib.utils import remove_outliers\n",
    "import lib.mapping as custom_maps\n",
    "\n",
    "import pickle\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "%matplotlib inline\n",
    "\n",
    "import pca as pca_custom\n",
    "\n",
    "DALEXBreakDown = dalex.predict_explanations._break_down.object.BreakDown\n",
    "DALEXShap = dalex.predict_explanations._shap.object.Shap"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0bfa0aa4",
   "metadata": {},
   "source": [
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a19adc",
   "metadata": {},
   "source": [
    "## Define notebook functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "387c6059",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(data: Dict[str, DALEXBreakDown | DALEXShap]) -> pd.DataFrame | None:\n",
    "    \"\"\"Retrieves model (regression) predictions for all analysed reservoirs from dalex\n",
    "    explainer objects\"\"\"\n",
    "    def confirm_type(data, data_type: DALEXBreakDown | DALEXShap):\n",
    "        return all([isinstance(value, data_type) for value in data.values()])\n",
    "    \n",
    "    predictions = None\n",
    "    if confirm_type(data, DALEXShap):\n",
    "        predictions = pd.DataFrame(\n",
    "            {'Reservoir': list(data.keys()),\n",
    "            'Prediction': [data[key].prediction for key in data]})\n",
    "    if confirm_type(data, DALEXBreakDown):\n",
    "        predictions = pd.DataFrame(\n",
    "            {'Reservoir': list(data.keys()),\n",
    "            'Prediction': [data[key].result['cumulative'].iloc[-1] for key in data]})\n",
    "    return predictions\n",
    "\n",
    "def process_features(\n",
    "        features: pd.DataFrame, predictions: pd.DataFrame, proportional: bool = False,\n",
    "        zero_mean: bool = True, unit_std: bool = False, abs_values: bool = False,\n",
    "        ) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\" \"\"\"\n",
    "    def drop_zero_cols(df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\" \"\"\"\n",
    "        return df.loc[:, (df != 0).any(axis=0)]\n",
    "        \n",
    "    features_with_predictions = pd.merge(\n",
    "        features_df, predictions, left_on='reservoir name', right_on='Reservoir')\n",
    "    reservoirs = features_with_predictions[['Reservoir']]\n",
    "    features_with_predictions.drop(columns='Reservoir', inplace=True)\n",
    "    if proportional:\n",
    "        features_num = features_with_predictions.iloc[:,1:]\\\n",
    "            .div(features_with_predictions['Prediction'], axis=0)\n",
    "    else:\n",
    "        features_num = features_with_predictions.iloc[:,1:]\n",
    "        \n",
    "    if abs_values:\n",
    "        features_num = features_num.abs()\n",
    "    \n",
    "    features_num = drop_zero_cols(features_num)\n",
    "    \n",
    "    if zero_mean:\n",
    "        means = features_num.mean()\n",
    "        features_num = features_num.sub(means)\n",
    "        \n",
    "    if unit_std:\n",
    "        std = features_num.std()\n",
    "        features_num = features_num.div(std)\n",
    "    \n",
    "    return reservoirs, features_num.drop(\n",
    "        columns=['Prediction', 'intercept', 'Unnamed: 1'], errors='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a2463d",
   "metadata": {},
   "source": [
    "## Define the analysis options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e01d11b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What gas is the analysis for?\n",
    "gas_name: Literal['co2', 'ch4'] = 'ch4'\n",
    "# Which feature importances are we using? - shap values or dalex breakdown future importances\n",
    "feature_type: Literal['shap', 'breakdown'] = 'breakdown'\n",
    "# On which model are the future importances based?\n",
    "model_name: Literal['xgboost', 'lightgbm', 'catboost'] = 'xgboost'\n",
    "# Name of the file with inputs, outputs and internal variables (re-emission output excel file)\n",
    "input_output_file: str = 'outputs_MIN_LOW_PRIM.xlsx'\n",
    "# Should the outliers be removed before attempting data scaling and PCA?\n",
    "run_outlier_removal = False\n",
    "## PCA OPTIONS\n",
    "scale_pca: bool = True\n",
    "pca_scaling_strategy = Normalizer\n",
    "## DISTANCE-BASED OPTIONS\n",
    "scale_dist: bool = False\n",
    "dist_scaling_strategy = MinMaxScaler\n",
    "# Use FA decomposition\n",
    "use_fa: bool = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a2801e7",
   "metadata": {},
   "source": [
    "## Load the required data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5fa9d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Load the input/output/internal_val data from reemission output EXCEL spreadsheet\n",
    "inputs_outputs_df = load_input_output(\n",
    "    filename=os.path.join('outputs','reemission', input_output_file),\n",
    "    sheets=('inputs', 'outputs', 'internals'))\n",
    "# 2. Load the features data, i.e. the features dataframe and the reservoir:explainer dictionary\n",
    "# First check if the values were recalculated in the previous notebook. If not, use precalculated values in\n",
    "# the bin/ folder\n",
    "try:\n",
    "    features_df, features_full = load_feature_importances(\n",
    "        gas_name, feature_type=feature_type, model_name=model_name, \n",
    "        folder = \"outputs/model_explanations\")\n",
    "except FileNotFoundError:\n",
    "    features_df, features_full = load_feature_importances(\n",
    "        gas_name, feature_type=feature_type, model_name=model_name, \n",
    "        folder = \"bin/model_explanations_precalculated\")    \n",
    "# 3. Find predictions from regression model (given in 'model_name') from dalex explainers\n",
    "predictions: pd.DataFrame = get_predictions(features_full)\n",
    "# 4. Pre-processes the features data, e.g. drops all-zero columns, scales to zero mean, unit_variance\n",
    "#    converts values to absolute and/or makes the values proportional to prediction\n",
    "#    Return two dataframes : one with reservoirs and the other one with processed features\n",
    "reservoirs, processed_features = process_features(\n",
    "    features_df, predictions, proportional = True, zero_mean=True, \n",
    "    unit_std = False, abs_values = False)\n",
    "# 5. Load input output data (only outputs - duplicate with 1)\n",
    "input_output_data = load_input_output(\n",
    "    filename=os.path.join('outputs','reemission', input_output_file),\n",
    "    sheets=('inputs',))\n",
    "# 6. Load models\n",
    "saved_model_folder = pathlib.Path('intermediate/shap_values/model_avg_feat_importances')\n",
    "with open(saved_model_folder / 'model_feats.pkl', 'rb') as fp:\n",
    "    model_feat_importances = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d34310b2",
   "metadata": {},
   "source": [
    "## I. Calculate and plot ranks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee2860c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model feature importance saved in DALEX\n",
    "model_importances, col_names = model_feat_importances[(model_name, gas_name)]\n",
    "importances_df = pd.DataFrame(data=model_importances, index=col_names)\\\n",
    "    .rename(columns={0:\"value\"})\\\n",
    "    .sort_values(by=\"value\", axis=0, ascending=False)\n",
    "importances_df['value'] = importances_df['value'] / importances_df['value'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd1309f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "importances_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd7f906d",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7753f48e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set reservoir names as index to limit the risk of errors when mapping indices to reservoir names\n",
    "features_df_res_name = features_df.set_index('reservoir name')\n",
    "\n",
    "if feature_type == 'shap':\n",
    "    cols_to_drop = [] # 'reservoir name'\n",
    "elif feature_type == 'breakdown':\n",
    "    cols_to_drop = ['intercept', 'Unnamed: 1'] # 'reservoir name'\n",
    "else:\n",
    "    cols_to_drop = []\n",
    "\n",
    "rank_df = get_ranks(\n",
    "    feature_data = features_df_res_name, cols_to_drop = cols_to_drop, \n",
    "    column_order = list(importances_df.index), # Make sure that the columns are in the same order as\n",
    "                                               # in the importances_df dataframe\n",
    "    sort_rows = True)\n",
    "plot_rank_heatmap(rank_data = rank_df, yticklabels = rank_df.index) #.loc[rank_df.index]['reservoir name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "196486cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "353cc1e4",
   "metadata": {},
   "source": [
    "## Calculate ranks distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a6664d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assert that the columns of rank_df align with the order of importances\n",
    "all(rank_df.columns == importances_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8cf621",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define correlation map between items\n",
    "# Uses 0-based indexing\n",
    "feature_corr_map = FeatureCorrelationMap(\n",
    "    cmap = {\n",
    "        (2,5): 0.7,\n",
    "        (6,9): 0.7,\n",
    "        (9, 11): 0.6})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e721553",
   "metadata": {},
   "source": [
    "### Calculate non-euclidean custom distance matrix using function `rank_distance_matrix`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e934b73",
   "metadata": {},
   "source": [
    "The custom distance metric is used to find similarities between reservoirs in the feature importance space based on the order of feature importances not the values of feature importances. The idea is that if reservoirs have the same feature importance ranks at the top they are similar.\n",
    "**NOTE:** May take a while to compute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a76eb64f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_matrix_df = rank_distance_matrix(\n",
    "    rank_df = rank_df, \n",
    "    rank_importances = importances_df,\n",
    "    corr = feature_corr_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a3a1ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_matrix_df = pd.DataFrame(dist_matrix_df, index=rank_df.index, columns = rank_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baff8beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_matrix_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9661624",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the distance matrix\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "sns.heatmap(\n",
    "    dist_matrix_df,\n",
    "    #yticklabels = features_df.loc[rank_df.index]['reservoir name'],\n",
    "    #xticklabels = features_df.loc[rank_df.index]['reservoir name'],\n",
    "    ax=ax)\n",
    "ax.tick_params(axis='x', labelsize=7)\n",
    "ax.tick_params(axis='y', labelsize=7)\n",
    "ax.set_xlabel(None)\n",
    "ax.set_ylabel(None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50aab6d0",
   "metadata": {},
   "source": [
    "## Check the loaded and pre-processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c81689ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_features.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a34928",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_output_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe9f977",
   "metadata": {},
   "outputs": [],
   "source": [
    "reservoirs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa736ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae37c69a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fig, ax = plt.subplots(figsize=(4,3))\n",
    "predictions\\\n",
    "    .rename(columns={'Prediction': 'CH$_4$ model predictions'})\\\n",
    "    .hist(figsize=(4,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "151c07aa",
   "metadata": {},
   "source": [
    "## Visualise reservoir's contributions using DALEX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea2a089",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "dropdown = widgets.Dropdown(\n",
    "    options=list(reservoirs['Reservoir']),\n",
    "    value='A Laing Ni Dam',\n",
    "    # rows=10,\n",
    "    description='Reservoirs:',\n",
    "    disabled=False\n",
    ")\n",
    "display(dropdown)\n",
    "features_full[dropdown.value].plot(show=False).show(renderer=\"browser\")\n",
    "\n",
    "selected_reservoir =dropdown.value\n",
    "def on_change(change):\n",
    "    global selected_reservoir\n",
    "    if change['type'] == 'change' and change['name'] == 'value':\n",
    "        selected_reservoir = change['new']\n",
    "        features_full[selected_reservoir].plot(show=False).show(renderer=\"browser\")\n",
    "        \n",
    "dropdown.observe(on_change, names='value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85926500",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframe of features for dimensionality reduction and clustering\n",
    "X_feat = processed_features.copy()\n",
    "y_feat = reservoirs.copy()\n",
    "# Dataframe of feature ranks per reservoir - also for dimensionality reduction and clustering\n",
    "X_ranks = rank_df.copy()\n",
    "y_ranks = rank_df.index.copy()\n",
    "# Dataframe of reservoir distances with respect to their feature rank orders\n",
    "X_dist = dist_matrix_df.copy()\n",
    "y_dist = dist_matrix_df.index.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6bdd9ab",
   "metadata": {},
   "source": [
    "## Remove outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e85c54b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_outlier_removal:\n",
    "    X_feat, y_feat = remove_outliers(X,y, num_neighbours = 200)\n",
    "    X_ranks, y_ranks = remove_outliers(X_ranks,y_ranks, num_neighbours = 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d029bfe3",
   "metadata": {},
   "source": [
    "## Run dimensionality reduction of the feature space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50604ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set scaling strategy\n",
    "scaling_strategy: None | Normalizer | StandardScaler | RobustScaler = Normalizer\n",
    "scaling_strategy_features = Normalizer\n",
    "\n",
    "# Dimensionality reduction in the feature importance space\n",
    "print(\"Running dimensionality reduction in the feature importance space\\n\")\n",
    "X_pca, y_pca, pca = dr.run_pca(\n",
    "    X_feat, y_feat, scaling_strategy = scaling_strategy_features)\n",
    "X_fa, y_fa, fa = dr.run_fa(\n",
    "    X_feat, y_feat, scaling_strategy = scaling_strategy_features)\n",
    "X_tsne, y_tsne, tsne = dr.run_tsne(\n",
    "    X_feat, y_feat, scaling_strategy = scaling_strategy_features)\n",
    "X_umap, y_umap, umap = dr.run_umap(\n",
    "    X_feat, y_feat, scaling_strategy = scaling_strategy_features, metric = 'euclidean',\n",
    "    min_dist = 0.05, n_components=3) # Alternatively choose metric = 'correlation'\n",
    "# Get the euclidean distance of X_feat\n",
    "X_feat_dist = euclidean_distances(X_feat)\n",
    "X_mds, y_mds, mds = dr.run_mds(\n",
    "    X_feat_dist, y_feat, scaling_strategy = None, n_components = 3,\n",
    "    dissimilarity = 'precomputed', metric = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8817e639",
   "metadata": {},
   "source": [
    "## Run dimensionality reduction of the feature rank space using PCoA and MDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "643ad69b",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaling_strategy_ranks = None\n",
    "print(\"Running dimensionality reduction in the feature rank space\\n\")\n",
    "print(\"Dimensionality reduction is performed on a custom matrix of distances between points\")\n",
    "# Note: X_pcoa_ranks is a dataframe but X_mds_ranks is a numpy.ndarray\n",
    "X_pcoa_ranks, y_pcoa_ranks, pcoa_model, pcoa_ranks = dr.run_pcoa(\n",
    "    X_dist, y_dist, scaling_strategy = scaling_strategy_ranks)\n",
    "X_mds_ranks, y_mds_ranks, mds_ranks = dr.run_mds(\n",
    "    X_dist, y_dist, scaling_strategy = scaling_strategy_ranks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bbaf464",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run custom PCA model\n",
    "# pca_custom_model = pca_custom.pca(n_components=len(list(processed_features.columns)))\n",
    "# pca_custom_results = pca_custom_model.fit_transform(X=X, row_labels=list(processed_features.columns))\n",
    "# pca_custom_results['explained_var']\n",
    "# fig, ax = pca_custom_model.biplot(n_feat=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f339424",
   "metadata": {},
   "source": [
    "## Explained and Cumulative Explained Variances from PCA on feature space and PCoA on feature rank space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "677e2d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,2, figsize = (8,4))\n",
    "fig.suptitle('Explained and Cumulative Explained Variances - PCA and PCoA')\n",
    "dr.explained_cumulative_var_plot(\n",
    "    ordination_model = pca, ax = ax[0], \n",
    "    num_components = 30, title='Feature Space')\n",
    "dr.explained_cumulative_var_plot(\n",
    "    ordination_model = pcoa_model, ax = ax[1],\n",
    "    xlabel = \"Number of coordinates\",\n",
    "    num_components = 30, title = 'Feature Rank Space')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15de98e0",
   "metadata": {},
   "source": [
    "## Map directions (vectors) from dim reduction to features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4dbd37b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map dimensionality reduction model directions (components) to data columns (features)\n",
    "# (DOES NOT WORK ON FEATURE RANKS AS THEY'RE COMPUTED USING A DISTANCE MATRIX)\n",
    "# PCA\n",
    "pca_to_feature_feats = dr.features_to_vars(\n",
    "    dim_red_model = pca, column_names = X_feat.columns)\n",
    "# FA\n",
    "if use_fa:\n",
    "    fa_to_feature_feats = dr.features_to_vars(\n",
    "        dim_red_model = fa, column_names = X_feat.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4446b8a",
   "metadata": {},
   "source": [
    "## Visualise the maps between dim reduction components (vectors) and features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4590c688",
   "metadata": {},
   "outputs": [],
   "source": [
    "dr.plot_component_feature_map(\n",
    "    pca_to_feature_feats, num_dims = 20, num_feats = None, xtick_rotation = 90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf977bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_fa:\n",
    "    dr.plot_component_feature_map(\n",
    "        fa_to_feature_ranks, num_dims = 20, num_feats = None, figsize=(14,4),\n",
    "        xtick_rotation = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "700f7804",
   "metadata": {},
   "source": [
    "## Find clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e53f897",
   "metadata": {},
   "source": [
    "### Plot point distances using K nearest neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c58bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1,1, figsize=(6,4))\n",
    "clust.plot_kneighbours_dist_graph(\n",
    "    X_pca, n_dim = 20, scaler=None, cutoff_line_value = 0.4, \n",
    "    title = 'K-Neighbours distances for features in PCA-reduced space', ax=axs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef8dd47",
   "metadata": {},
   "source": [
    "## Cluster feature data in the PCA reduced space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad769e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if scale_pca:\n",
    "    X_pca_feat_clustering = pca_scaling_strategy().fit_transform(X_pca)\n",
    "else:\n",
    "    X_pca_feat_clustering = X_pca\n",
    "\n",
    "n_clusters_feat: int = 3\n",
    "\n",
    "print(\"CLUSTERING FEATURES.....\\n\")\n",
    "kmeans_labels_feat = clust.run_kmeans(\n",
    "    X_pca_feat_clustering, n_dim = None, n_clusters = n_clusters_feat)\n",
    "\n",
    "hdbscan_labels_feat, hdbscan_probabilities_feat = clust.run_hdbscan(\n",
    "    X_pca_feat_clustering, n_dim = None, min_samples = 50)\n",
    "\n",
    "bgmm_labels_feat = clust.run_bgmm(\n",
    "    X_pca_feat_clustering, n_dim = None, n_clusters = n_clusters_feat)\n",
    "\n",
    "optics_labels_feat = clust.run_optics(\n",
    "    X_pca_feat_clustering, n_dim = None, min_samples = 0.02, xi = 0.05, metric=\"minkowski\",\n",
    "    cluster_method = 'xi',\n",
    "    min_cluster_size = 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a298836",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clustering methods not used in the analysis\n",
    "# Reasons: DBSCAN is a bit fiddly with parameterization. HDBSCAN used instead as it seems to be alleviating\n",
    "#          the shortcomings of DBSCAN whilst being a method superseding the original DBSCAN\n",
    "#          GMM gives the same results as BGMM and thus BGMM is used instead\n",
    "# dbscan_labels_feat = clust.run_dbscan(\n",
    "#    X_pca_feat_clustering, min_samples = 30, n_dim = None, eps=0.4)\n",
    "#gmm_labels_feat = clust.run_gmm(\n",
    "#    X_pca_feat_clustering, n_dim = None, n_clusters = n_clusters_feat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f96115e4",
   "metadata": {},
   "source": [
    "## Cluster rank data in the PCoA reduced space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6735c47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if scale_pca:\n",
    "    X_pcoa_rank_clustering = pca_scaling_strategy().fit_transform(X_pcoa_ranks)\n",
    "else:\n",
    "    X_pcoa_rank_clustering = X_pcoa_ranks\n",
    "\n",
    "n_clusters_rank: int = 6\n",
    "        \n",
    "print(\"CLUSTERING RANKS...\\n\")\n",
    "kmeans_labels_rank = clust.run_kmeans(\n",
    "    X_pcoa_rank_clustering, n_dim = None, n_clusters = n_clusters_rank, col_name = 'cluster')\n",
    "\n",
    "hdbscan_labels_rank, hdbscan_probabilities_rank = clust.run_hdbscan(\n",
    "    X_pcoa_rank_clustering, n_dim = None, min_samples = 10)\n",
    "\n",
    "bgmm_labels_rank = clust.run_bgmm(\n",
    "    X_pcoa_rank_clustering, n_dim = None, n_clusters = n_clusters_rank,\n",
    "    init_params = 'kmeans')\n",
    "\n",
    "optics_labels_rank = clust.run_optics(\n",
    "    X_pcoa_rank_clustering, n_dim = None, min_samples = 0.02, xi = 0.05, metric=\"minkowski\",\n",
    "    cluster_method = 'xi',\n",
    "    min_cluster_size = 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc94873",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clustering methods not used in the analysis\n",
    "# Reasons: DBSCAN is a bit fiddly with parameterization. HDBSCAN used instead as it seems to be alleviating\n",
    "#          the shortcomings of DBSCAN whilst being a method superseding the original DBSCAN\n",
    "#          GMM gives the same results as BGMM and thus BGMM is used instead\n",
    "#dbscan_labels_rank = clust.run_dbscan(\n",
    "#    X_pcoa_rank_clustering, min_samples = 30, n_dim = None, eps=0.4)\n",
    "#gmm_labels_rank = clust.run_gmm(\n",
    "#    X_pcoa_rank_clustering, n_dim = None, n_clusters = n_clusters_rank)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9cab801",
   "metadata": {},
   "source": [
    "## Cluster rank data using the distance matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f06205f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if scale_dist:\n",
    "    X_dist_clustering = dist_scaling_strategy().fit_transform(X_dist)\n",
    "else:\n",
    "    X_dist_clustering = X_dist\n",
    "\n",
    "n_clusters_rank: int = 6\n",
    "\n",
    "kmedoids_labels_rank_dist = clust.run_kmedoids(\n",
    "    X_dist, n_clusters = n_clusters_rank, n_dim = None, metric=\"precomputed\",\n",
    "    method='alternate', random_state = 42)\n",
    "    \n",
    "hdbscan_labels_rank_dist, hdbscan_probabilities_rank_dist = clust.run_hdbscan(\n",
    "    X_dist, n_dim = None, min_samples = 10, metric=\"precomputed\", alpha=0.001,\n",
    "    min_cluster_size = 3, cluster_selection_epsilon=0.01)\n",
    "    \n",
    "optics_labels_rank_dist = clust.run_optics(\n",
    "    X_dist, n_dim = None, min_samples = 0.08, xi = 0.05, metric=\"precomputed\",\n",
    "    cluster_method = 'xi',\n",
    "    min_cluster_size = 0.5)\n",
    "\n",
    "agg_labels_rank_dist = clust.run_agglomerative(\n",
    "        X_dist, n_dim = None, n_clusters = n_clusters_rank,\n",
    "        metric = 'precomputed',\n",
    "        distance_threshold = None, col_name = 'cluster') # 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6219b80a",
   "metadata": {},
   "source": [
    "## Visualise feature data in reduced space\n",
    "*K-Means*, *HDBSCAN*, *GMM*, *BGMM* clusterings of features in 4x4 subplots in *t-SNE*, *FA*, *UMAP*, *MDS* and *PCA* projected spaces (5 plots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "857e341e",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_1: str = \"K-Means clusters\"\n",
    "title_2: str = \"HDBSCAN clusters\"\n",
    "title_3: str = \"BGMM clusters\"\n",
    "title_4: str = \"OPTICS clusters\"\n",
    "    \n",
    "default_alpha = 0.65"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06aa191e",
   "metadata": {},
   "source": [
    "### t-SNE reduced feature space - features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64eeccc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-Means, HDBSCAN, GMM, BGMM clusterings of features in 4x4 subplots in t-SNE space\n",
    "s_multiplier = 30\n",
    "fig, axs = plt.subplots(2,2, figsize = (8,6))\n",
    "fig.suptitle(f\"Visualisation of clusters of features in t-SNE projected space - {gas_name.upper()} emissions\")\n",
    "clust.visualise_clusters_2D(\n",
    "        data = X_tsne, labels = kmeans_labels_feat, s_multiplier = s_multiplier, title = title_1,\n",
    "        probabilities = None, ax = axs.flat[0], default_alpha = default_alpha)\n",
    "clust.visualise_clusters_2D(\n",
    "        data = X_tsne, labels = hdbscan_labels_feat, s_multiplier = s_multiplier, title = title_2, \n",
    "        probabilities = hdbscan_probabilities_feat, ax = axs.flat[1], default_alpha = default_alpha)\n",
    "clust.visualise_clusters_2D(\n",
    "        data = X_tsne, labels = bgmm_labels_feat, s_multiplier = s_multiplier, title = title_3,\n",
    "        probabilities = None, ax = axs.flat[2], default_alpha = default_alpha)\n",
    "clust.visualise_clusters_2D(\n",
    "        data = X_tsne, labels = optics_labels_feat, s_multiplier = s_multiplier, title = title_4,\n",
    "        probabilities = None, ax = axs.flat[3], default_alpha = default_alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "646b60da",
   "metadata": {},
   "source": [
    "### FA reduced feature space - features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89723dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_multiplier = 75\n",
    "fig, axs = plt.subplots(2,2, figsize = (8,6))\n",
    "fig.suptitle(f\"Visualisation of clusters of features in FA projected space - {gas_name.upper()} emissions\")\n",
    "clust.visualise_clusters_2D(\n",
    "        data = X_fa, labels = kmeans_labels_feat, s_multiplier = s_multiplier, title = title_1,\n",
    "        probabilities = None, ax = axs.flat[0], default_alpha = default_alpha)\n",
    "clust.visualise_clusters_2D(\n",
    "        data = X_fa, labels = hdbscan_labels_feat, s_multiplier = s_multiplier, title = title_2, \n",
    "        probabilities = hdbscan_probabilities_feat, ax = axs.flat[1], default_alpha = default_alpha)\n",
    "clust.visualise_clusters_2D(\n",
    "        data = X_fa, labels = bgmm_labels_feat, s_multiplier = s_multiplier, title = title_3,\n",
    "        probabilities = None, ax = axs.flat[2], default_alpha = default_alpha)\n",
    "clust.visualise_clusters_2D(\n",
    "        data = X_fa, labels = optics_labels_feat, s_multiplier = s_multiplier, title = title_4,\n",
    "        probabilities = None, ax = axs.flat[3], default_alpha = default_alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e892f964",
   "metadata": {},
   "source": [
    "### PCA reduced feature space - features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "315dce9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_multiplier = 300\n",
    "fig, axs = plt.subplots(2,2, figsize = (8,6))\n",
    "fig.suptitle(f\"Visualisation of clusters of features in PCA projected space - {gas_name.upper()} emissions\")\n",
    "clust.visualise_clusters_2D(\n",
    "        data = X_pca, labels = kmeans_labels_feat, s_multiplier = s_multiplier, title = title_1,\n",
    "        probabilities = None, ax = axs.flat[0], default_alpha = default_alpha)\n",
    "clust.visualise_clusters_2D(\n",
    "        data = X_pca, labels = hdbscan_labels_feat, s_multiplier = s_multiplier, title = title_2, \n",
    "        probabilities = hdbscan_probabilities_feat, ax = axs.flat[1], default_alpha = default_alpha)\n",
    "clust.visualise_clusters_2D(\n",
    "        data = X_pca, labels = bgmm_labels_feat, s_multiplier = s_multiplier, title = title_3,\n",
    "        probabilities = None, ax = axs.flat[2], default_alpha = default_alpha)\n",
    "clust.visualise_clusters_2D(\n",
    "        data = X_pca, labels = optics_labels_feat, s_multiplier = s_multiplier, title = title_4,\n",
    "        probabilities = None, ax = axs.flat[3], default_alpha = default_alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1028a33",
   "metadata": {},
   "source": [
    "### MDS reduced feature space - features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caff9112",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_multiplier = 50\n",
    "fig, axs = plt.subplots(2,2, figsize = (8,6))\n",
    "fig.suptitle(f\"Visualisation of clusters of features in MDS projected space - {gas_name.upper()} emissions\")\n",
    "clust.visualise_clusters_2D(\n",
    "        data = X_mds, labels = kmeans_labels_feat, s_multiplier = s_multiplier, title = title_1,\n",
    "        probabilities = None, ax = axs.flat[0], default_alpha = default_alpha)\n",
    "clust.visualise_clusters_2D(\n",
    "        data = X_mds, labels = hdbscan_labels_feat, s_multiplier = s_multiplier, title = title_2, \n",
    "        probabilities = hdbscan_probabilities_feat, ax = axs.flat[1], default_alpha = default_alpha)\n",
    "clust.visualise_clusters_2D(\n",
    "        data = X_mds, labels = bgmm_labels_feat, s_multiplier = s_multiplier, title = title_3,\n",
    "        probabilities = None, ax = axs.flat[2], default_alpha = default_alpha)\n",
    "clust.visualise_clusters_2D(\n",
    "        data = X_mds, labels = optics_labels_feat, s_multiplier = s_multiplier, title = title_4,\n",
    "        probabilities = None, ax = axs.flat[3], default_alpha = default_alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51290a17",
   "metadata": {},
   "source": [
    "### UMAP reduced feature space - features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d53264",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_multiplier = 10\n",
    "fig, axs = plt.subplots(2,2, figsize = (8,6))\n",
    "fig.suptitle(f\"Visualisation of clusters of features in UMAP projected space - {gas_name.upper()} emissions\")\n",
    "clust.visualise_clusters_2D(\n",
    "        data = X_umap, labels = kmeans_labels_feat, s_multiplier = s_multiplier, title = title_1,\n",
    "        probabilities = None, ax = axs.flat[0], default_alpha = default_alpha)\n",
    "clust.visualise_clusters_2D(\n",
    "        data = X_umap, labels = hdbscan_labels_feat, s_multiplier = s_multiplier, title = title_2, \n",
    "        probabilities = hdbscan_probabilities_feat, ax = axs.flat[1], default_alpha = default_alpha)\n",
    "clust.visualise_clusters_2D(\n",
    "        data = X_umap, labels = bgmm_labels_feat, s_multiplier = s_multiplier, title = title_3,\n",
    "        probabilities = None, ax = axs.flat[2], default_alpha = default_alpha)\n",
    "clust.visualise_clusters_2D(\n",
    "        data = X_umap, labels = optics_labels_feat, s_multiplier = s_multiplier, title = title_4,\n",
    "        probabilities = None, ax = axs.flat[3], default_alpha = default_alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cba89d5",
   "metadata": {},
   "source": [
    "## Ranks\n",
    "*K-Means*, *HDBSCAN*, *GMM*, *BGMM* clusterings of ranks 4x4 subplots in *t-SNE*, *FA* and *PCA* projected spaces (3 plots)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc5c9ad",
   "metadata": {},
   "source": [
    "### A. Clustering made in PCoA space projected onto PCoA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b37361e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-Means, HDBSCAN, GMM, BGMM clusterings of ranks in 4x4 subplots in t-SNE space\n",
    "s_multiplier = 500\n",
    "fig, axs = plt.subplots(2,2, figsize = (8,6))\n",
    "fig.suptitle(f\"Visualisation of clusters of ranks in PCoA projected space - {gas_name.upper()} emissions\")\n",
    "clust.visualise_clusters_2D(\n",
    "        data = X_pcoa_ranks.to_numpy(), labels = kmeans_labels_rank, s_multiplier = s_multiplier, title = title_1,\n",
    "        probabilities = None, ax = axs.flat[0], default_alpha = default_alpha)\n",
    "clust.visualise_clusters_2D(\n",
    "        data = X_pcoa_ranks.to_numpy(), labels = hdbscan_labels_rank, s_multiplier = s_multiplier, title = title_2, \n",
    "        probabilities = hdbscan_probabilities_rank, ax = axs.flat[1], default_alpha = default_alpha)\n",
    "clust.visualise_clusters_2D(\n",
    "        data = X_pcoa_ranks.to_numpy(), labels = bgmm_labels_rank, s_multiplier = s_multiplier, title = title_3,\n",
    "        probabilities = None, ax = axs.flat[2], default_alpha = default_alpha)\n",
    "clust.visualise_clusters_2D(\n",
    "        data = X_pcoa_ranks.to_numpy(), labels = optics_labels_rank, s_multiplier = s_multiplier, title = title_4,\n",
    "        probabilities = None, ax = axs.flat[3], default_alpha = default_alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "164022b4",
   "metadata": {},
   "source": [
    "### B. Clustering made in PCoA space projected onto MDS space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70018356",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_multiplier = 80\n",
    "fig, axs = plt.subplots(2,2, figsize = (8,6))\n",
    "fig.suptitle(f\"Visualisation of clusters of ranks in MDS projected space - {gas_name.upper()} emissions\")\n",
    "clust.visualise_clusters_2D(\n",
    "        data = X_mds_ranks, labels = kmeans_labels_rank, s_multiplier = s_multiplier, title = title_1,\n",
    "        probabilities = None, ax = axs.flat[0], default_alpha = default_alpha)\n",
    "clust.visualise_clusters_2D(\n",
    "        data = X_mds_ranks, labels = hdbscan_labels_rank, s_multiplier = s_multiplier, title = title_2, \n",
    "        probabilities = hdbscan_probabilities_rank, ax = axs.flat[1], default_alpha = default_alpha)\n",
    "clust.visualise_clusters_2D(\n",
    "        data = X_mds_ranks, labels = bgmm_labels_rank, s_multiplier = s_multiplier, title = title_3,\n",
    "        probabilities = None, ax = axs.flat[2], default_alpha = default_alpha)\n",
    "clust.visualise_clusters_2D(\n",
    "        data = X_mds_ranks, labels = optics_labels_rank, s_multiplier = s_multiplier, title = title_4,\n",
    "        probabilities = None, ax = axs.flat[3], default_alpha = default_alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5fefe8b",
   "metadata": {},
   "source": [
    "## CLUSTERING ON A DISTANCE MATRIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f46c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_1: str = \"K-Medoids clusters\"\n",
    "title_2: str = \"HDBSCAN clusters\"\n",
    "title_3: str = \"OPTICS clusters\"\n",
    "title_4: str = \"Aggregated Clustering clusters\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb006806",
   "metadata": {},
   "source": [
    "### PCoA space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d2cccba",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_multiplier = 500\n",
    "fig, axs = plt.subplots(2,2, figsize = (8,6))\n",
    "fig.suptitle(f\"Visualisation of clusters of ranks in PCoA projected space - {gas_name.upper()} emissions\")\n",
    "clust.visualise_clusters_2D(\n",
    "        data = X_pcoa_ranks.to_numpy(), labels = kmedoids_labels_rank_dist, s_multiplier = s_multiplier, title = title_1,\n",
    "        probabilities = None, ax = axs.flat[0], default_alpha = default_alpha)\n",
    "clust.visualise_clusters_2D(\n",
    "        data = X_pcoa_ranks.to_numpy(), labels = hdbscan_labels_rank_dist, s_multiplier = s_multiplier, title = title_2, \n",
    "        probabilities = hdbscan_probabilities_rank_dist, ax = axs.flat[1], default_alpha = default_alpha)\n",
    "clust.visualise_clusters_2D(\n",
    "        data = X_pcoa_ranks.to_numpy(), labels = optics_labels_rank_dist, s_multiplier = s_multiplier, title = title_3,\n",
    "        probabilities = None, ax = axs.flat[2], default_alpha = default_alpha)\n",
    "clust.visualise_clusters_2D(\n",
    "        data = X_pcoa_ranks.to_numpy(), labels = agg_labels_rank_dist, s_multiplier = s_multiplier, title = title_4,\n",
    "        probabilities = None, ax = axs.flat[3], default_alpha = default_alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e61eee",
   "metadata": {},
   "source": [
    "### MDS space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1661668",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_multiplier = 100\n",
    "fig, axs = plt.subplots(2,2, figsize = (8,6))\n",
    "fig.suptitle(f\"Visualisation of clusters of ranks in MDS projected space - {gas_name.upper()} emissions\")\n",
    "clust.visualise_clusters_2D(\n",
    "        data = X_mds_ranks, labels = kmedoids_labels_rank_dist, s_multiplier = s_multiplier, title = title_1,\n",
    "        probabilities = None, ax = axs.flat[0], default_alpha = default_alpha)\n",
    "clust.visualise_clusters_2D(\n",
    "        data = X_mds_ranks, labels = hdbscan_labels_rank_dist, s_multiplier = s_multiplier, title = title_2, \n",
    "        probabilities = hdbscan_probabilities_rank_dist, ax = axs.flat[1], default_alpha = default_alpha)\n",
    "clust.visualise_clusters_2D(\n",
    "        data = X_mds_ranks, labels = optics_labels_rank_dist, s_multiplier = s_multiplier, title = title_3,\n",
    "        probabilities = None, ax = axs.flat[2], default_alpha = default_alpha)\n",
    "clust.visualise_clusters_2D(\n",
    "        data = X_mds_ranks, labels = agg_labels_rank_dist, s_multiplier = s_multiplier, title = title_4,\n",
    "        probabilities = None, ax = axs.flat[3], default_alpha = default_alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d57f3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "hdbscan_rank_dist_labels = clusterer_ranks_dist.labels_\n",
    "hdbscan_rank_dist_labels_df = pd.DataFrame(hdbscan_rank_dist_labels, columns=['cluster'])\n",
    "hdbscan_rank_dist_probabilities_df = pd.DataFrame(clusterer_ranks_dist.probabilities_, columns=['probability'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dfbbe1f",
   "metadata": {},
   "source": [
    "# MAKE DETAILED PCA VISUALISATIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac71120",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "importlib.reload(clust)\n",
    "figure_output_folder = pathlib.Path(\"figures/clustering\")\n",
    "if not figure_output_folder.exists():\n",
    "    figure_output_folder.mkdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab37905d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1,2, figsize = (12,5))\n",
    "fig.suptitle(\n",
    "    f\"K-Means derived clusters in PCA / PCoA reduced feature space - {gas_name.upper()} emissions\",\n",
    "    fontsize=16)\n",
    "clust.visualise_pca_2D(\n",
    "    data=X_pca, labels=kmeans_labels_feat, pca_model=pca, s_multiplier = 400,\n",
    "    label_fontsize = 14,\n",
    "    arrow_width = 0.0225,\n",
    "    tick_fontsize = 12,\n",
    "    probabilities =None,\n",
    "    default_alpha = 0.6,\n",
    "    num_components = 4,\n",
    "    title = 'Features',\n",
    "    legend_location = 'lower left',\n",
    "    var_names = list(X_feat.columns), ax=axs.flat[0])\n",
    "clust.visualise_pca_2D(\n",
    "    data=X_pcoa_ranks.to_numpy(), labels=kmeans_labels_rank, pca_model=pcoa_model, \n",
    "    s_multiplier = 400,\n",
    "    label_fontsize = 14,\n",
    "    tick_fontsize = 12,\n",
    "    title = 'Feature ranks',\n",
    "    probabilities =None,\n",
    "    default_alpha = 0.6,\n",
    "    legend_location = 'lower right',\n",
    "    var_names = list(X_ranks.columns), ax=axs.flat[1])\n",
    "fig.savefig(figure_output_folder/\"Kmeans_clusters_ch4.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7587fc55",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fig, axs = plt.subplots(1,2, figsize = (12,5))\n",
    "#fig.suptitle(\n",
    "#    f\"HDBSCAN derived clusters in PCA reduced rank space - {gas_name.upper()} emissions\",\n",
    "#    fontsize=16)\n",
    "#clust.visualise_pca_2D(\n",
    "#    data=X_pca, labels=hdbscan_labels_feat, pca_model=pca, s_multiplier = 300, \n",
    "#    probabilities = hdbscan_probabilities_feat,\n",
    "#    default_alpha = 0.8,\n",
    "#    title = 'Features',\n",
    "#    var_names = list(X_feat.columns), ax=axs.flat[0])\n",
    "#clust.visualise_pca_2D(\n",
    "#    data=X_pca_ranks, labels=hdbscan_labels_rank, pca_model=pca_ranks, s_multiplier = 300, #hdbscan\n",
    "#    title = 'Ranks',\n",
    "#    probabilities = hdbscan_probabilities_rank,\n",
    "#    default_alpha = 0.8,\n",
    "#    var_names = list(X_ranks.columns), ax=axs.flat[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbed6b63",
   "metadata": {},
   "source": [
    "## Save results for mapping in R\n",
    "Make sure to run without outlier removal so that all reservoirs are being processed\n",
    "Choose best number of clusters for \n",
    "Information to save (for each gas)\n",
    "1. Ranks with reservoir names\n",
    "2. K-Means clusters with features\n",
    "3. K-Means clusters with ranks\n",
    "4. HDBSCAN clusters for features\n",
    "5. HDBSCAN clusters for ranks\n",
    "6. BGMM clusters for features\n",
    "7. BGMM clusters for rnaks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09141470",
   "metadata": {},
   "source": [
    "## CURRENTLY ONLY SAVES DATA FROM THE PCA/PCoA PLOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "429abc0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLDER_NAME = pathlib.Path(\"intermediate/density_mapping\")\n",
    "feat_kmeans_clusters = pd.concat([y_feat, kmeans_labels_feat], axis = 1)\n",
    "rank_kmeans_clusters = pd.concat([pd.Series(y_dist), kmeans_labels_rank],  axis = 1)\n",
    "ch4_output_folder = FOLDER_NAME / 'ch4'\n",
    "if not ch4_output_folder.exists():\n",
    "    ch4_output_folder.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "feat_kmeans_clusters.to_excel(ch4_output_folder / 'k_means_clusters_feat.xlsx')\n",
    "rank_kmeans_clusters.to_excel(ch4_output_folder / 'k_means_clusters_rank.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec1b203a",
   "metadata": {},
   "source": [
    "# MAPPING RESERVOIR CLUSTER DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faba4ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_option: Literal['pca', 'hdbscan', 'gmm'] = 'kmeans'\n",
    "# Create data structures\n",
    "    \n",
    "cluster_labels = {\n",
    "    'kmeans': (kmeans_labels_feat, kmeans_labels_rank),\n",
    "    'hdbscan': (hdbscan_labels_feat, hdbscan_labels_rank),\n",
    "    'bgmm': (bgmm_labels_feat, bgmm_labels_rank)}\n",
    "\n",
    "cluster_data_feat = pd.concat([y_feat,X_feat,cluster_labels[cluster_option][0]], axis=1)\n",
    "cluster_data_rank = pd.concat([pd.Series(y_dist),X_ranks,cluster_labels[cluster_option][1]], axis=1)\n",
    "\n",
    "if cluster_option == 'hdbscan':\n",
    "    cluster_data_feat = pd.concat([cluster_data_feat, hdbscan_probabilities_feat], axis=1)\n",
    "    cluster_data_rank = pd.concat([cluster_data_rank, hdbscan_probabilities_rank], axis=1)\n",
    "\n",
    "# Currently only works with data that has not undergone any prior outlier removal\n",
    "data_map_feat = cluster_data_feat.merge(\n",
    "    inputs_outputs_df, left_on = 'Reservoir', right_on = 'Name').drop(columns='Name')\n",
    "data_map_feat['cluster'] = data_map_feat['cluster'].fillna(-1)\n",
    "data_map_rank = cluster_data_rank.merge(\n",
    "    inputs_outputs_df, left_on = 'reservoir name', right_on = 'Name').drop(columns='Name')\n",
    "data_map_rank['cluster'] = data_map_rank['cluster'].fillna(-1)\n",
    "\n",
    "# using dictionary to convert specific columns\n",
    "dtype_conversion_map = {'res_mean_depth': float,\n",
    "                'cluster': 'category',\n",
    "                'catch_area_fractions_1': float,\n",
    "                'res_max_depth': float}\n",
    " \n",
    "data_map_feat = data_map_feat.astype(dtype_conversion_map)\n",
    "data_map_rank = data_map_rank.astype(dtype_conversion_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5735820",
   "metadata": {},
   "source": [
    "### Plot a folium map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc906904",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_maps.plot_mya_reservoirs_gdf(data_map_feat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b560664c",
   "metadata": {},
   "source": [
    "### Plot static maps with clustering results both in feature and rank space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4497ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "fig, axs = plt.subplots(1,2, figsize = (8,8))\n",
    "fig.suptitle(f\"Reservoir clusters obtained with {cluster_option.upper()} clustering method\")\n",
    "custom_maps.plot_mya_reservoirs_static(\n",
    "    data = data_map_feat, ax=axs.flat[0], title=\"Clusters in feature importance space\",\n",
    "    marker_size = 'res_max_depth')\n",
    "custom_maps.plot_mya_reservoirs_static(\n",
    "    data = data_map_rank, ax=axs.flat[1], title=\"Clusters in rank space\",\n",
    "    marker_size = 'res_max_depth')\n",
    "fig.tight_layout()\n",
    "fig.show()\n",
    "fig.savefig(figure_output_folder/\"reservoir_cluster_map.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4382d135",
   "metadata": {},
   "source": [
    "### Plot dynamic maps in Bokeh with clustering results both in feature and rank space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9db0af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_maps.plot_with_bokeh(\n",
    "    data_map_feat, marker_size = 'res_max_depth', marker_size_multiplier = 2,\n",
    "    title = f\"Clusters in the feature space derived with {cluster_option.upper()}\",\n",
    "    tooltips = [('Cluster','cluster'),\n",
    "            ('Name','Reservoir'),\n",
    "            ('Type', 'type'),\n",
    "            ('Volume','res_volume'),\n",
    "            ('Net CO2 emission','co2_net'),\n",
    "            ('Net CH4 emission','ch4_net')])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a806e9e",
   "metadata": {},
   "source": [
    "# UNUSED CODE BELOW... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ef10e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20539b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyComplexHeatmap import *\n",
    "plt.figure(figsize=(8, 4))\n",
    "col_ha = HeatmapAnnotation(\n",
    "    df=pca_to_feature.iloc[0:20,:],plot=True,legend=True,legend_gap=5,hgap=0.5,axis=1, cmap='RdYlBu_r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc2d03c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unused but required import for doing 3d projections with matplotlib < 3.2\n",
    "\n",
    "\n",
    "fig = plt.figure(1, figsize=(8, 6))\n",
    "plt.clf()\n",
    "ax = fig.add_subplot(111, projection=\"3d\", elev=20, azim=60)\n",
    "ax.set_position([0.5, 0.5, 1, 1])\n",
    "\n",
    "#ax = Axes3D(fig)\n",
    "\n",
    "plt.cla()\n",
    "\n",
    "\"\"\"\n",
    "for name, label in [(\"Setosa\", 0), (\"Versicolour\", 1), (\"Virginica\", 2)]:\n",
    "    ax.text3D(\n",
    "        X[y == label, 0].mean(),\n",
    "        X[y == label, 1].mean() + 1.5,\n",
    "        X[y == label, 2].mean(),\n",
    "        name,\n",
    "        horizontalalignment=\"center\",\n",
    "        bbox=dict(alpha=0.5, edgecolor=\"w\", facecolor=\"w\"),\n",
    "    )\n",
    "\n",
    "# Reorder the labels to have colors matching the cluster results\n",
    "y = np.choose(y, [1, 2, 0]).astype(float)\n",
    "\"\"\"\n",
    "\n",
    "ax.scatter(\n",
    "    X_pca[:, 0], X_pca[:, 1], X_pca[:, 2], s=200*X_pca[:, 3], c=pca_labels['cluster'],   #X_pca[:, 3], \n",
    "    edgecolor='grey', alpha=0.7)\n",
    "#cmap=plt.cm.nipy_spectral, \n",
    "\n",
    "ax.xaxis.set_ticklabels([])\n",
    "ax.yaxis.set_ticklabels([])\n",
    "ax.zaxis.set_ticklabels([])\n",
    "\n",
    "plt.xlabel('Principal component 1')\n",
    "plt.ylabel('Principal component 2')\n",
    "ax.set_zlabel('Principal component 3', fontsize=10, rotation=0)\n",
    "#ax.set_xlim(-20, 40)\n",
    "#ax.set_ylim(-20, 15)\n",
    "#ax.set_zlim(-20, 8)\n",
    "#plt.tight_layout()\n",
    "#plt.legend()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b6d3d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pca_df = pd.DataFrame(X_pca, columns = [f'PC_{num}' for num in range(0,X_pca.shape[1])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15677c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pca_df['PC_4_abs'] = X_pca_df['PC_4'].abs()\n",
    "X_pca_df['cluster'] = pca_labels_df['cluster_number']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdffcb30",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pca_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ff1ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "X_pca_df_filt = X_pca_df.query('PC_1 < 150')\n",
    "\n",
    "fig = px.scatter_3d(X_pca_df_filt, x='PC_0', y='PC_1', z='PC_2',\n",
    "              color='PC_3', size='PC_4_abs', opacity=0.7, symbol='cluster')\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14cbd4e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skbio.stats.ordination import pcoa\n",
    "pcoa_ranks = pcoa(dist_matrix_df, number_of_dimensions=4, )\n",
    "pcoa_ranks.proportion_explained\n",
    "dist_matrix_df.index\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "df_pcoa_ranks = pcoa_ranks.samples[['PC1', 'PC2', 'PC3', 'PC4']]\n",
    "df_pcoa_ranks.index = dist_matrix_df.index\n",
    "point_sizes = MinMaxScaler().fit_transform(df_pcoa_ranks[['PC3']])\n",
    "# Add names\n",
    "df_pcoa_ranks = df_pcoa_ranks.join(features_df[['reservoir name']])\n",
    "#df_pcoa_ranks = pd.merge(df_pcoa_ranks, features_df[['reservoir name']], left_index=True, right_index=True)\n",
    "#df_pcoa_ranks['res IDs'] = dist_matrix_df.index.to_numpy()\n",
    "#df_pcoa_ranks = df_pcoa_ranks.set_index('reservoir name')\n",
    "fig, ax = plt.subplots(figsize=(8,6))\n",
    "#ax.set_xlim([-0.27, 0])\n",
    "#ax.set_ylim([-0.27, 0.27])\n",
    "df_pcoa_ranks.plot(\n",
    "    'PC1', 'PC2', kind='scatter', ax=ax, c='lightblue', s=500*point_sizes, alpha=0.6, edgecolor='k')\n",
    "res_names = features_df.loc[rank_df.index]['reservoir name']\n",
    "ax.set_xlim([-0.8, 1])\n",
    "ax.set_ylim([-0.6, 0.8])\n",
    "\n",
    "\n",
    "#for label, x, y in zip(col1.index, col1, col2):\n",
    "#    texts+=[ax.text(x, y, label, color=groupColors.get(langnameGroup[label],'k'), fontsize=8)] # for adjustText\n",
    "from adjustText import adjust_text\n",
    "texts = []\n",
    "for k, v in df_pcoa_ranks.iterrows():\n",
    "    texts.append(plt.text(v['PC1'], v['PC2'], s=v['reservoir name'], alpha = 0.7, fontsize=8))\n",
    "adjust_text(texts, ax = ax, arrowprops=dict(arrowstyle=\"-\", color='k', lw=0.3, alpha=0.3), expand_objects =(1.2, 1.2),\n",
    "            #force_text = (0.25, 0.25),\n",
    "            expand_text=(1.2, 1.2))\n",
    "#for k, v in df_pcoa_ranks.iterrows():\n",
    "#    ax.annotate(v['reservoir name'], v[['PC1', 'PC2']], alpha = 0.4, fontsize=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b1a95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "symbols_dict = dict(zip(range(0,8), symbols))\n",
    "symbols_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ecbd17e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_labels_num = pca_labels_df['cluster_number'].map(symbols_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef3c41b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_labels_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1e883a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "symbols = ['circle', 'cross', 'diamond', 'square', 'x',\n",
    "            'circle-open', 'diamond-open', 'square-open']\n",
    "symbols_dict = dict(zip(range(0,8), symbols))\n",
    "symbols_list_full = []\n",
    "\n",
    "fig = go.Figure(data=[go.Scatter3d(\n",
    "    x=X_pca[:, 0],\n",
    "    y=X_pca[:, 1],\n",
    "    z=X_pca[:, 2],\n",
    "    mode='markers',\n",
    "    marker=dict(\n",
    "        size=2*np.abs(X_pca[:, 3]),\n",
    "        color=X_pca[:, 4],                # set color to an array/list of desired values\n",
    "        colorscale='Viridis',   # choose a colorscale\n",
    "        symbol=pca_labels_num,\n",
    "        opacity=0.8,\n",
    "        line=dict(width=1, color='black')\n",
    "    ),\n",
    ")])\n",
    "\n",
    "# tight layout\n",
    "fig.update_layout(margin=dict(l=0, r=0, b=0, t=0))\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
