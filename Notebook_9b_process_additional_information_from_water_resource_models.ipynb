{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c7bdcc8a",
   "metadata": {},
   "source": [
    "# Processing of outputs from water resources models with reservoir level, turbine flow and spill recorders\n",
    "\n",
    "### Tomasz Janus\n",
    "### 11/04/2024"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d685f30",
   "metadata": {},
   "source": [
    "### TODO\n",
    "1. fetch excel outputs from pywr\n",
    "2. fetch a list of hp sites with ror/sto status from data generated in the previous notebook\n",
    "3. parse excel output columns to obtain reservoir names\n",
    "4. fetch a reservoir/turbine parameters from models such that we can calculate composite features such as ratio of head to max head, etc.\n",
    "4. summarise and group and save in a json/yaml/toml file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb5349f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "import pathlib\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc3bf0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_paths\n",
    "file_folder = pathlib.Path(\"outputs/pywr_sim_aligned_models_with_levels/\")\n",
    "file_irrawaddy = file_folder  / \"outputs_irrawaddy_hist_with_flow_rec.xlsx\"\n",
    "file_salween = file_folder / \"outputs_salween_hist_with_flow_rec.xlsx\"\n",
    "file_sittaung = file_folder / \"outputs_sittaung_hist_with_flow_rec.xlsx\"\n",
    "\n",
    "# Get series of mean values of all recorded columns - required fo find mean HP, spill and \n",
    "# level for each reservoir\n",
    "df_irrawaddy = pd.read_excel(file_irrawaddy, skiprows=[2]).drop(index=0).mean(numeric_only=True)\n",
    "df_salween = pd.read_excel(file_salween, skiprows=[2]).drop(index=0).mean(numeric_only=True)\n",
    "df_sittaung = pd.read_excel(file_sittaung, skiprows=[2]).drop(index=0).mean(numeric_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b97e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "turbine_pattern = r'[tT]urbine'\n",
    "\n",
    "def megam3d_to_m3s(flow: float) -> float:\n",
    "    \"\"\"Convert between flows in Mm3/d (from pywr water resources model) to m3/s\"\"\"\n",
    "    return flow * 1e6 / 24 / 3_600 \n",
    "\n",
    "def reservoir_name_from_turbine_node(node_name: str) -> str | None:\n",
    "    \"\"\" \"\"\"\n",
    "    pattern = r'([\\w\\s()]+?)_(?:turbine|Turbine)(?:_|$)|(?:turbine|Turbine)_(.+)$'\n",
    "    match = re.search(pattern, node_name)\n",
    "    if match:\n",
    "        return match.group(1).strip() if match.group(1) else match.group(2).strip()\n",
    "    return None\n",
    "\n",
    "def add_with_summation(data: Dict[str, float], key: str, value: float) -> None:\n",
    "    \"\"\" \"\"\"\n",
    "    if key in data.keys():\n",
    "        data[key] += value\n",
    "    else:\n",
    "        data[key] = value\n",
    "    \n",
    "def get_data_from_pywr_outputs(results: pd.DataFrame) -> Dict:\n",
    "    \"\"\" \"\"\"\n",
    "    outputs_dict = dict()\n",
    "    for name, value in results.items():\n",
    "\n",
    "        if \":energy\" in name:\n",
    "            processed_energy_recorder = name.replace(\":energy\", \"\")\n",
    "            processed_energy_recorder = re.sub(turbine_pattern, '', processed_energy_recorder)\\\n",
    "                .replace(\"_\", \"\").strip()\n",
    "            processed_energy_recorder += \"_hp\"\n",
    "            add_with_summation(outputs_dict, processed_energy_recorder, value)\n",
    "\n",
    "        if \"LevelRec\" in name:\n",
    "            processed_level_recorder = name.replace(\"LevelRec\", \"\").replace(\"_\", \"\").strip()\n",
    "            processed_level_recorder += \"_level\"\n",
    "            add_with_summation(outputs_dict, processed_level_recorder, value)\n",
    "\n",
    "        if \"FlowRec\" in name:\n",
    "            processed_flow_recorder = name.replace(\"FlowRec\", \"\")\n",
    "            processed_flow_recorder = re.sub(turbine_pattern, '', processed_flow_recorder)\\\n",
    "                .replace(\"_\", \"\").strip()    \n",
    "            if processed_flow_recorder.lower().find(\"spill\") != -1  or \\\n",
    "                    processed_flow_recorder.lower().find(\"controlspill\") != -1:\n",
    "                suffix = \"_spillflow\"\n",
    "                spill_pattern = r'([sS]pill|[cC]ontrol[cS]pill)'\n",
    "                processed_flow_recorder = re.sub(spill_pattern, '', processed_flow_recorder)\\\n",
    "                    .replace(\"_\", \"\").strip()\n",
    "            else:\n",
    "                suffix = \"_flow\"\n",
    "            processed_flow_recorder += suffix\n",
    "            add_with_summation(outputs_dict, processed_flow_recorder, value)\n",
    "    return outputs_dict\n",
    "\n",
    "def convert_output_dict_to_df(output_dict: Dict) -> pd.DataFrame:\n",
    "    \"\"\" \"\"\"\n",
    "    rec_df = pd.DataFrame.from_dict(output_dict, orient=\"index\")\n",
    "    rec_df_transpose = rec_df.transpose()\n",
    "    rec_df_transpose.columns = rec_df_transpose.columns.str.split('_', expand = True)\n",
    "    rec_df_transpose.columns.names = [None, 'Reservoir']\n",
    "    output_df = rec_df_transpose.stack(-1).reset_index().set_index(\"Reservoir\")\n",
    "    cols_to_drop = [col for col in output_df.columns if 'irrigation' in col.lower()]\n",
    "    cols_to_drop.append('level_0')\n",
    "    output_df = output_df.drop(columns=cols_to_drop)\n",
    "    output_df = output_df.transpose()\n",
    "    return output_df\n",
    "\n",
    "def extract_data_from_pywr_model(model_path: pathlib.Path) -> pd.DataFrame:\n",
    "    \"\"\" \"\"\"\n",
    "    with open(model_path, 'r') as json_file:\n",
    "        model = json.load(json_file)\n",
    "    # Initialize reservoir dictionary:\n",
    "    res_dict = dict()\n",
    "    # Get the reservoir node parameters\n",
    "    for node in model['nodes']:\n",
    "        if node['type'] != \"storage\":\n",
    "            continue\n",
    "        res_params = {\n",
    "            'status': node['comment'] if 'comment' in node else \"unknown\",\n",
    "            'min_vol': node['min_volume'] if 'min_volume' in node else 0.0,\n",
    "            'max_vol': node['max_volume']\n",
    "        }\n",
    "        res_dict[node['name']] = res_params    \n",
    "    # Get the reservoir/turbine data from model parameters\n",
    "    for reservoir in res_dict.keys():\n",
    "        for par_name, par_data in model['parameters'].items():\n",
    "            if par_name == \"__\"+reservoir+\"__:max_power_flow\":\n",
    "                res_dict[reservoir].update({\"turbine_elevation\": par_data['turbine_elevation']})\n",
    "            if par_name == \"__\"+reservoir+\"__:power_capacity\":\n",
    "                res_dict[reservoir].update({\"capacity\": par_data['value']})\n",
    "            # We also need to find max_level\n",
    "            if par_name == \"__\"+reservoir+\"__:level\":\n",
    "                max_level = max(par_data[\"values\"])\n",
    "                res_dict[reservoir].update({\"max_level\": max_level})    \n",
    "    # Convert res_dict to a dataframe and return it\n",
    "    return pd.DataFrame(res_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dca4b7af",
   "metadata": {},
   "source": [
    "### 1. Get the flow, hp production and level data from water resources models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb20554",
   "metadata": {},
   "outputs": [],
   "source": [
    "sittaung_dict = get_data_from_pywr_outputs(df_sittaung)\n",
    "salween_dict = get_data_from_pywr_outputs(df_salween)\n",
    "irrawaddy_dict = get_data_from_pywr_outputs(df_irrawaddy)\n",
    "# 1. Process sittaung\n",
    "output_df_sittaung = convert_output_dict_to_df(sittaung_dict)\n",
    "# There's a doubling of names: `Paung Laung (Upper)` and `Paung Laung (upper)`\n",
    "doubled_reservoir_sittaung = \"Paung Laung (upper)\"\n",
    "output_df_sittaung.loc['Paung Laung (Upper)', 'spillflow'] += \\\n",
    "    output_df_sittaung.loc[doubled_reservoir_sittaung, 'spillflow']\n",
    "output_df_sittaung.drop(doubled_reservoir_sittaung, inplace=True)\n",
    "# 2. Process salween\n",
    "output_df_salween = convert_output_dict_to_df(salween_dict)\n",
    "# 3. Process irrrawaddy\n",
    "output_df_irrawaddy = convert_output_dict_to_df(irrawaddy_dict)\\\n",
    "    .drop([\"Mandalay\", \"YangonDomesticWater\"])\n",
    "\n",
    "out_res_map = {\n",
    "    \"MongTon\" : \"Mong Ton\"\n",
    "}\n",
    "\n",
    "out_combined = pd.concat([\n",
    "    output_df_irrawaddy,\n",
    "    output_df_salween,\n",
    "    output_df_sittaung], axis=0).rename(index=out_res_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d442554",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_combined.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f9550bb",
   "metadata": {},
   "source": [
    "### 2. Get the reservoir/turbine parameters from the pywr water resources file(s)\n",
    "**IMPORTANT NOTE:** The water resources models are not shared in this repository. Therefore the code below is private and only works on the Author's computer. We keep this code for reference but normally, this code will be skipper and the data will be read from the pre-saved .csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af7ea58",
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_from_pywr_models: bool = False # ONLY SET TO TRUE IF YOU HAVE ACCESS TO THE PYWR MODELS, \n",
    "                                       # OTHERWISE SET TO FALSE\n",
    "file_path = pathlib.Path(\"inputs/pywr_res_turbine_parameters\")\n",
    "file_name: str = \"res_turbine_parameters_pywr.xlsx\"\n",
    "\n",
    "# We need to map some reservoir names because of inconsistent reservoir naming in the pywr models\n",
    "# of Myanmar. The names in nodes do not correspond to the names 'embedded' in the parameter/recorder \n",
    "# names. Therefore we need to rename some of the reservoir such that there are no doubled rows after\n",
    "# merging with the dataframe with pywr model outputs\n",
    "par_res_map = {\n",
    "    \"Lemro_1\": \"Lemro1\",\n",
    "    \"Lemro_2\": \"Lemro2\",\n",
    "    \"ManTong\": \"Mantong\",\n",
    "    \"Nam_Paw\": \"Nam Paw\",\n",
    "    \"Mi_Chaung\": \"MiChaung\",\n",
    "    \"Saing_Din\": \"SaingDin\"\n",
    "}\n",
    "\n",
    "if extract_from_pywr_models:\n",
    "    os.makedirs(file_path, exist_ok = True)\n",
    "    ### Get the information from the model - max_hp_capacity, max_level, turbine_elevation\n",
    "    # Produce the table and erase the code!!\n",
    "    irr_model_path = pathlib.Path(\n",
    "        \"/home/lepton/Documents/git_projects/myanmar_hydro/models/\" +\n",
    "        \"sim_hp_recorders_new_pywr_aligned_flow_level_recorders/irrawaddy/\" +\n",
    "        \"Irrawaddy_pywr_historical_southampton_new_Kc.json\")\n",
    "    sal_model_path = pathlib.Path(\n",
    "        \"/home/lepton/Documents/git_projects/myanmar_hydro/models/\" +\n",
    "        \"sim_hp_recorders_new_pywr_aligned_flow_level_recorders/salween/\" +\n",
    "        \"Salween_pywr_historical_southampton_new_Kc.json\")\n",
    "    sit_model_path = pathlib.Path(\n",
    "        \"/home/lepton/Documents/git_projects/myanmar_hydro/models/\" +\n",
    "        \"sim_hp_recorders_new_pywr_aligned_flow_level_recorders/sittaung/\" +\n",
    "        \"Sittaung_pywr_historical_southampton_new_Kc.json\")\n",
    "    # Remove reservoirs in the models that are not HP\n",
    "    par_data_irr = extract_data_from_pywr_model(irr_model_path).drop(\n",
    "        columns=['Yangon_Domestic_Water','Mandalay_Domestic_Water'])\n",
    "    par_data_sal = extract_data_from_pywr_model(sal_model_path).drop(\n",
    "        columns=['Moe Byal_Irrigation_Reservoir'])\n",
    "    par_data_sit = extract_data_from_pywr_model(sit_model_path).drop(\n",
    "        columns=['Sinthe_Irrigation_Reservoir','Ngalaik_Irrigation_Reservoir', \n",
    "                 'Yezin_Irrigation_Reservoir','Chaungmange_Irrigation_Reservoir',\n",
    "                 'Ngamoeyeik_Irrigation_Reservoir'])\n",
    "    par_combined = pd.concat([par_data_irr, par_data_sal, par_data_sit], axis=1)\n",
    "    par_combined.to_excel(file_path/file_name)\n",
    "else:\n",
    "    # Read from pre-saved excel file\n",
    "    par_combined = pd.read_excel(file_path/file_name)\n",
    "par_combined = par_combined\\\n",
    "    .rename(columns={\"Unnamed: 0\" : \"Reservoir\"})\\\n",
    "    .set_index(\"Reservoir\")\\\n",
    "    .transpose()\\\n",
    "    .rename(index=par_res_map)\n",
    "par_combined.loc[\"Paung Laung (Lower)\"]['turbine_elevation'] = 104\n",
    "par_combined.loc[\"Paung Laung (Middle)\"]['turbine_elevation'] = 174\n",
    "par_combined.loc[\"Paung Laung (Upper)\"]['turbine_elevation'] = 273\n",
    "par_combined.loc[\"Mong Ton\"]['turbine_elevation'] = 220\n",
    "par_combined.loc[\"Nam Paw\"]['turbine_elevation'] = 756.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c944327e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine outputs and parameters into a single dataframe\n",
    "out_par = pd.merge(out_combined, par_combined, how = \"outer\", left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "185d4486",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_par.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03d97ad8",
   "metadata": {},
   "source": [
    "### 3. Get emission estimates afrom intermediate pre-calculated data in the earlier steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdec15b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the earlier pre-calculated data from excel file\n",
    "emissions_df = pd.read_excel(\n",
    "    pathlib.Path('intermediate/hp_multi_ror_emissions_and_generation.xlsx'))\\\n",
    "    .drop(columns=['geometry']).rename(columns={\"name\": \"Reservoir\"})\\\n",
    "    .set_index(\"Reservoir\")\n",
    "emissions_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12fb0e69",
   "metadata": {},
   "source": [
    "### 4. Combine the three datasets and save to excel/yaml/json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12bd3a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_par_merge = out_par.rename(\n",
    "    index = {\n",
    "        \"Baluchaung1\": \"Baluchaung 1\",\n",
    "        \"Baluchaung2\": \"Baluchaung 2\",\n",
    "        \"Baluchaung3\": \"Baluchaung 3\",\n",
    "        \"Baluchaung (Upper)\": \"Baluchaung (upper)\",\n",
    "        \"Shweli1\" : \"Shweli 1\",\n",
    "        \"Shweli2\" : \"Shweli 2\",\n",
    "        \"Shweli3\" : \"Shweli 3\",\n",
    "        \"Upper Yeywa\": \"Yeywa (upper)\",\n",
    "        \"Middle Yeywa\": \"Yeywa (middle)\",\n",
    "        'Upper Buywa' : \"Buywa (upper)\",\n",
    "        'Upper Sedawgyi' : \"Sedawgyi (upper)\",\n",
    "        'SaingDin': \"Saing Din\",\n",
    "        \"Paung Laung (Lower)\": \"Lower Paunglaung\",\n",
    "        \"Paung Laung (Middle)\": \"Paung Laung (middle)\",\n",
    "        \"Paung Laung (Upper)\": \"Upper Paunglaung\",\n",
    "        \"Hawkham (Upper)\": \"Hawkham (upper)\",\n",
    "        'Zawgyi1' : \"Zawgyi I\",\n",
    "        'Zawgyi2' : \"Zawgyi II\",\n",
    "        \"Nam Pawn (Lower)\" : \"Nam Pawn (lower)\",\n",
    "        \"Nam Pawn (Upper)\": \"Nam Pawn (upper)\",\n",
    "        \"Lemro1\": \"Lemro 1\",\n",
    "        \"Lemro2\": \"Lemro 2\",\n",
    "        \"Thapanzeik\": \"Thaphanseik\",\n",
    "        'Keng Tawng (Upper)' : \"Keng Tawng (upper)\",\n",
    "        \"MiChaung\": \"Mi Chaung\"\n",
    "    })\n",
    "out_par_em = pd.merge(\n",
    "    out_par_merge, emissions_df, how = \"inner\", \n",
    "    left_index=True, right_index=True)\n",
    "out_par_em.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f3cf3e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Processed HP sites: {len(out_par_em)} out of {len(out_par)} in pywr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf36f86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that there are no nan values on the merged columns suggesting that we either haven't \n",
    "# got all the values from the model files or that we didn't sort out all the reservoir naming conventions\n",
    "# prior to data merging and there are some repeated rows, e.g. Baluchaung 1 and Baluchaung1, etc.\n",
    "nan_mask = pd.isnull(out_par_em[['flow', 'hp', 'level', 'spillflow', 'turbine_elevation']]).any(axis=1)\n",
    "try:\n",
    "    assert len(out_par_em[nan_mask]) == 0\n",
    "    print(\"Everything is fine, we're good to go\")\n",
    "except AssertionError:\n",
    "    print(\"There are Nan values in some of the rows, indicating missing data. See below.\")\n",
    "    print(out_par_em[nan_mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f4f30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    \"Reservoir for which emissions are related to only a fraction of hp generation\\n\"+\n",
    "    \"due to their multipurpose nature\")\n",
    "out_par_em[out_par_em['hp_fraction']<1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c7312bf",
   "metadata": {},
   "source": [
    "### 5. Join with IFC data such that we can compare HP generation against the installed capacity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca2ec9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ifc_db = gpd.read_file(pathlib.Path(\"bin/gis_layers/ifc_database/all_dams_replaced_refactored.shp\"))\\\n",
    "    .loc[:,[\"ID\", \"IFC_ID\", 'DAM_NAME', 'DAM_HEIGHT', 'FSL (m)', 'LWL (m)', 'HRT',\n",
    "           'Des_Head', 'Des_Disch', 'STOR_MCM',\n",
    "           'Inst_cap', 'Annual Gen', 'RIV_ORD','geometry']]\\\n",
    "    .rename(columns={\"DAM_NAME\": \"Reservoir\"})\\\n",
    "    .set_index(\"Reservoir\")\n",
    "out_par_em_ifc = pd.merge(out_par_em, ifc_db, how = \"left\", left_index=True, right_index=True)\\\n",
    "    .astype({'ID': 'int', 'IFC_ID' : 'int', 'RIV_ORD': 'int'})\n",
    "# Add new columns (variables) quantifying the factors driving emission factors in hydroelectric reservoirs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef16037",
   "metadata": {},
   "source": [
    "**Methodology explanation**\n",
    "Hydropower generation $\\begin{equation} G_{HP} \\propto Q \\times (H - z_t) \\end{equation}$, where $Q$ is the flow via the turbine, $H$ is the water head and $z_t$ is the turbine elevation.\n",
    "Emission intensity of a hydroelectric plant $\\begin{equation}E_{GHG} = \\displaystyle\\frac{(e_{CO_2} + e_{CH_4})*A}{G_{HP}} \\end{equation}$.\n",
    "In the absence of any limitations imposed by the limited capacity of the transmission network, the hydroelectric plant will produce the maximum amount of electricity if it's operating near the maximum design head at a maximum flow such that the operation is near the turbines' maximum capacity at all times. Operational inefficiencies of a hydroelectric plant will result from sub-optimal operation, e.g. operating at low head, loosing significant volumes of water via spills and overflow as well as from the environmental conditions, i.e. reduced water inflows from the catchment and the river network, e.g. due to changes in the atmospheric conditions or land use, and increased flow variability, e.g. perdiods of excessively large flows necessitating water releases via overflows followed by periods of draughts. We quantify the potential sub-optimality of HP operation using the following indices.\\\n",
    "**1. Plant factor** :\n",
    "$\\begin{equation}PF = \\cfrac{\\bar{G_{HP}}}{G_{HP,max}} \\end{equation}$ \\\n",
    "**2. Level Headroom** : \n",
    "$\\begin{equation}1 - \\displaystyle\\frac{\\bar{H}-z_t}{z_{max} - z_t}\\end{equation}$ \\\n",
    "**3. Flow Headroom** :\n",
    "$\\begin{equation}1 - \\displaystyle\\frac{\\bar{Q_t}}{Q_{t,max}}\\end{equation}$ \\\n",
    "**4. Utility Flow Fraction** :\n",
    "$\\begin{equation} \\displaystyle\\frac{Q_t}{Q_t + Q_{spill}} \\end{equation}$\n",
    "\n",
    "**Estimate power production figure as**:\n",
    "\n",
    "$\\begin{equation}\n",
    "    G_{HP} = k \\times \\displaystyle\\left( Q_{t,max}\\times\\frac{\\bar{Q_t}}{Q_{t,max}} \\right)\\,\n",
    "    \\left( \\left(H_{max} - z_t\\right)\\times\\frac{\\bar{H}-z_t}{H_{max} - z_t} \\right)\n",
    "\\end{equation}$\n",
    "\n",
    "$\\begin{equation} \\dot{M}_{GHG} = \\left(e_{CO_2} + e_{CH_4}\\right) \\times A\\end{equation}$\n",
    "\n",
    "$\\begin{equation}\n",
    "    E_{GHG} = \\displaystyle\\frac{\\dot{M}_{GHG}}{G_{HP}}\n",
    "\\end{equation}$\n",
    "\n",
    "**Factors for ML model:** $Q_{t,max}$ ,$\\displaystyle\\frac{\\bar{Q_t}}{Q_{t,max}}$, $H_{max} - z_t$,\n",
    "$\\displaystyle\\frac{\\bar{H}-z_t}{H_{max} - z_t}$, $\\left(e_{CO_2} + e_{CH_4}\\right)$, $A$\n",
    "\n",
    "**ISSUE** We do not have the information about the maximum flow, but we have information about design power generation. Therefore we calculate the maximum flow from maximum head and installed capacity using the following equation:\n",
    "\n",
    "$\\begin{equation} Q_{t,max} = \\displaystyle\\frac{G_{HP,des}}{H_{max} - z_t} \\end{equation}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b8f512",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HP_des = Hmax * Qdes -> Qdes = HP_des/Hmax\n",
    "# Calculate the conversion coefficient\n",
    "# Flow in Mm3/d\n",
    "# HP in MW\n",
    "# Head in m\n",
    "# HP[MW] = flow[m3/s] * h[m] * 1000kg/m3 * 9.81 m2/s * 0.9 / 1e6\n",
    "# flow[m3/s] = HP[MW] / h[m] * 1000 / (9.81 * 0.9)\n",
    "# flow[Mm3/d] = flow[m3/s] * 3600 * 24 / 1000000\n",
    "# flow[Mm3/d] = HP[MW] / h[m] * 1000 / (9.81 * 0.8) * 3600 * 24 / 1000000 = \n",
    "#               HP[MW] / h[m] * 24 * 3.6 / (9.81 * 0.8)\n",
    "f_flow_hp = 24 * 3.6 / (9.81 * 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e28ff4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_par_em_ifc['level_headroom'] = 1 - (out_par_em_ifc['level'] - out_par_em_ifc['turbine_elevation'])/\\\n",
    "    (out_par_em_ifc['max_level'] - out_par_em_ifc['turbine_elevation'])\n",
    "out_par_em_ifc['flow_headroom'] = 1 - out_par_em_ifc['flow'].apply(megam3d_to_m3s) / out_par_em_ifc['Des_Disch']\n",
    "out_par_em_ifc['plant_factor'] = out_par_em_ifc['hp'] / out_par_em_ifc['Inst_cap']\n",
    "out_par_em_ifc['total_flow'] = out_par_em_ifc['flow'] + out_par_em_ifc['spillflow']\n",
    "out_par_em_ifc['f_utility_flow'] = out_par_em_ifc['flow'] / out_par_em_ifc['total_flow']\n",
    "\n",
    "out_par_em_ifc['des_head'] = out_par_em_ifc['max_level'] - out_par_em_ifc['turbine_elevation']\n",
    "out_par_em_ifc['des_flow'] = out_par_em_ifc['Inst_cap'] / out_par_em_ifc['des_head'] * f_flow_hp\n",
    "# Calculate factors for the ML model\n",
    "# 1. des_flow\n",
    "# 2. q_mean_des\n",
    "out_par_em_ifc['q_mean_des']  = out_par_em_ifc['flow'] / out_par_em_ifc['des_flow']\n",
    "# 3. des_head\n",
    "# 4. h_mean_des\n",
    "out_par_em_ifc['h_mean_des']  = (out_par_em_ifc['level'] - out_par_em_ifc['turbine_elevation']) / \\\n",
    "    out_par_em_ifc['des_head'] \n",
    "# 5. tot_em_net\n",
    "# 6. res_area (cross-check against r_area_km2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "921e347f",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_par_em_ifc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf7717a",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_par_em_ifc[out_par_em_ifc['ID'].isna()]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f7bf89aa",
   "metadata": {},
   "source": [
    "RIV_ORD : River order. River order is here defined and calculated based on the long-term average\n",
    "discharge (DIS_AV_CMS) using logarithmic progression:\n",
    "1 = > 100000\n",
    "2 = 10000 – 100000\n",
    "3 = 1000 – 10000\n",
    "4 = 100 – 1000\n",
    "5 = 10 – 100\n",
    "6 = 1 - 10\n",
    "7 = 0.1 - 1\n",
    "8 = 0.01 - 0.1\n",
    "9 = 0.001 - 0.0\n",
    "HYDROAtlas (Linke et al.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c3b104",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_par_em_ifc_gdf = gpd.GeoDataFrame(\n",
    "    out_par_em_ifc, geometry=out_par_em_ifc['geometry'], crs=\"EPSG:4326\")\n",
    "out_par_em_ifc.to_excel(pathlib.Path(\"intermediate/out_par_em_ifc.xlsx\"))\n",
    "out_par_em_ifc_gdf.to_file(pathlib.Path('intermediate/out_par_em_ifc.shp'))\n",
    "out_par_em_ifc_gdf.to_file(pathlib.Path('intermediate/out_par_em_ifc.geojson', driver=\"GeoJSON\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "758e5076",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
